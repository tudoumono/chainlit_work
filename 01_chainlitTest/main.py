"""
main.py ï¼ Chainlit + OpenAI (ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œ)
================================================

â— è¿½åŠ æ©Ÿèƒ½
------------------------------------------------
* ç’°å¢ƒå¤‰æ•° DEBUG_MODE=1 ã§ **ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰** ã«åˆ‡æ›¿
  - OpenAI ã¸ã¯ã‚¢ã‚¯ã‚»ã‚¹ã—ãªã„
  - ä»£ã‚ã‚Šã«ã€Œãƒ€ãƒŸãƒ¼å¿œç­”ã€ã‚’è¿”ã™ï¼ˆAPIæ–™é‡‘ã‚¼ãƒ­ï¼‰
  - ã‚³ãƒ¼ãƒ‰ã®å‹•ä½œç¢ºèªã‚„ UI ãƒ†ã‚¹ãƒˆã«ä¾¿åˆ©

â— DEBUG_MODE ã®åˆ‡ã‚Šæ›¿ãˆæ–¹æ³•
------------------------------------------------
Windows (PowerShell) :
    $env:DEBUG_MODE="1"; poetry run chainlit run main.py

macOS / Linux :
    DEBUG_MODE=1 poetry run chainlit run main.py

.env ã‚’ä½¿ã†å ´åˆï¼ˆæœ¬ç•ªã¯ 0ã€é–‹ç™ºæ™‚ã¯ 1 ãªã©ï¼‰:
    DEBUG_MODE=1

â— å‚è€ƒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
------------------------------------------------
* Chainlit Decorators & Classes:  
  https://docs.chainlit.io/api-reference
* OpenAI Chat Completions:  
  https://platform.openai.com/docs/api-reference/chat
"""

# --- æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---------------------------------------------------------
import os
from datetime import datetime
from pathlib import Path
import json

# --- ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ --------------------------------------------------------
from dotenv import load_dotenv
import chainlit as cl
from openai import AsyncOpenAI

# =============================================================================
# 1. åˆæœŸè¨­å®š
# =============================================================================
load_dotenv()                                              # .env ã‚’èª­ã¿è¾¼ã¿
DEBUG_MODE = os.getenv("DEBUG_MODE", "0") == "1"           # ãƒ‡ãƒãƒƒã‚°åˆ¤å®š
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))  # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

# =============================================================================
# 2. OpenAI ã¸å•ã„åˆã‚ã›ã‚‹ãƒ˜ãƒ«ãƒ‘é–¢æ•°
# =============================================================================
async def ask_openai(
    client: AsyncOpenAI,
    user_message: str,
    history: list[dict] | None = None,
    model: str = "gpt-4o-mini",
    temperature: float = 0.7,
    max_tokens: int = 1024,
):
    """
    Chat Completion ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å–å¾—ã€‚
    DEBUG_MODE æ™‚ã¯ OpenAI ã‚’å‘¼ã°ãšã«ãƒ€ãƒŸãƒ¼å¿œç­”ã‚’è¿”ã™ã€‚
    """
    if DEBUG_MODE:
        # ---------- ãƒ‡ãƒãƒƒã‚°ï¼šãƒ€ãƒŸãƒ¼ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’è¿”ã™ ----------
        async def fake_stream():
            # OpenAI ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®å½¢å¼ã«ç°¡æ˜“çš„ã«ä¼¼ã›ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ yield
            class DummyDelta:
                def __init__(self, content): self.content = content

            class DummyChoice:
                def __init__(self, content): self.delta = DummyDelta(content)

            class DummyChunk:
                def __init__(self, content): self.choices = [DummyChoice(content)]

            # å®Ÿéš›ã¯å°‘ã—ãšã¤æ–‡ç« ã‚’é€ã‚‹
            for part in ["ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰", "ã“ã‚Œã¯ ", "OpenAI ã‚’ ", "å‘¼ã³å‡ºã—ã¦ ", "ã„ã¾ã›ã‚“ã€‚"]:
                yield DummyChunk(part)
        return fake_stream()

    # ---------- é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ï¼šOpenAI ã¸å•ã„åˆã‚ã› ----------
    messages = (history or []) + [{"role": "user", "content": user_message}]
    return await client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
        stream=True,
    )

# =============================================================================
# 3. ãƒãƒ£ãƒƒãƒˆé–‹å§‹æ™‚
# =============================================================================
@cl.on_chat_start
async def start():
    """
    ãƒ«ãƒ¼ãƒ ç”Ÿæˆç›´å¾Œã« 1 å›ã ã‘å®Ÿè¡Œã€‚
    ãƒ‡ãƒãƒƒã‚°æ™‚ã¯ãƒ¢ãƒ¼ãƒ‰è¡¨ç¤ºã‚’è¿½åŠ ã€‚
    """
    prefix = "ğŸ› ï¸ã€ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã€‘\n" if DEBUG_MODE else ""
    await cl.Message(
        content=f"{prefix}è³ªå•ã—ã¦ãã ã•ã„ï¼š",
        actions=[cl.Action(name="save", value="save", label="ä¿å­˜", payload={})],
    ).send()

# =============================================================================
# 4. ã€Œä¿å­˜ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚
# =============================================================================
@cl.action_callback("save")
async def save_history_to_file(action: cl.Action):
    """
    ä¼šè©±å±¥æ­´ (chat_history) ã‚’ JSON ã«ä¿å­˜ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’æç¤ºã€‚
    """
    history = cl.user_session.get("chat_history", [])
    if not history:
        return

    log_dir = Path("chatlogs")
    log_dir.mkdir(exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    file_name = f"session_{timestamp}.json"
    log_file = log_dir / file_name

    with log_file.open("w", encoding="utf-8") as f:
        json.dump(history, f, indent=2, ensure_ascii=False)

    await cl.Message(
        content="ã“ã®ãƒãƒ£ãƒãƒ«ã§ã®ã‚„ã‚Šå–ã‚Šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚",
        elements=[cl.File(name=file_name, path=str(log_file), display="inline")],
    ).send()

# =============================================================================
# 5. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†
# =============================================================================
@cl.on_message
async def on_message(message: cl.Message):
    """
    1) å±¥æ­´å–å¾— â†’ 2) ask_openai å‘¼ã³å‡ºã— (ãƒ‡ãƒãƒƒã‚°æ™‚ã¯ãƒ€ãƒŸãƒ¼) â†’ 3) ã‚¹ãƒˆãƒªãƒ¼ãƒ è¡¨ç¤º
    """
    # ----- 1) ä¼šè©±å±¥æ­´ã‚’å–å¾—ã—ãƒ¦ãƒ¼ã‚¶ç™ºè¨€ã‚’è¿½åŠ  ------------------------------
    history: list[dict] = cl.user_session.get("chat_history", [])
    history.append({"role": "user", "content": message.content})

    # ç”»é¢ã«ç©ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç½®ãå¾Œã§ update()
    stream_msg = await cl.Message(content="").send()

    try:
        # ----- 2) ask_openaiï¼ˆå†…éƒ¨ã§ãƒ‡ãƒãƒƒã‚°åˆ¤å®šï¼‰ -------------------------
        stream = await ask_openai(client, user_message=message.content, history=history)

        assistant_text = ""  # GPT ç”Ÿæˆæ–‡ã‚’è“„ç©

        # ----- 3) ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é€æ¬¡å—ä¿¡ã— UI æ›´æ–° --------------------------
        async for chunk in stream:
            delta = chunk.choices[0].delta.content
            if delta:
                assistant_text += delta
                stream_msg.content += delta
                await stream_msg.update()

        # GPT å®Œäº†å¾Œã«å±¥æ­´ã¸è¿½åŠ 
        history.append({"role": "assistant", "content": assistant_text})

    except Exception as e:
        await cl.Message(content=f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}").send()

    finally:
        # å±¥æ­´ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¸ä¿å­˜
        cl.user_session.set("chat_history", history)

        # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‹ä¿å­˜ãƒœã‚¿ãƒ³
        await cl.Message(
            content="âœ… å¿œç­”å®Œäº†ï¼æ¬¡ã®æ“ä½œã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
            actions=[cl.Action(name="save", value="save", label="ä¿å­˜", payload={})],
        ).send()
