"""
main.py ï¼ Chainlit + OpenAI ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª
=========================================
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒãƒ£ãƒƒãƒˆ UI ãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ã€‚
åˆ©ç”¨è€…ã¯ã€ŒGPTâ€‘3.5 / GPTâ€‘4 / GPTâ€‘4oã€ã‚’é€”ä¸­ã§ã‚‚è‡ªç”±ã«åˆ‡ã‚Šæ›¿ãˆã¦å¯¾è©±ã§ãã¾ã™ã€‚

--------------------------------------------------------------------------
ğŸ’¡ â€œã–ã£ãã‚Šå…¨ä½“åƒâ€
--------------------------------------------------------------------------
1. **åˆæœŸåŒ–**      : ãƒ¦ãƒ¼ã‚¶è¨­å®š(JSON)ã‚’èª­ã¿è¾¼ã¿ï¼ˆâ€» .env ã¯èª­ã¿è¾¼ã¾ãªã„ï¼‰
2. **ãƒ¢ãƒ‡ãƒ«é¸æŠUI**: èµ·å‹•æ™‚ã«ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºï¼ˆ`show_model_selection()`ï¼‰
3. **ãƒãƒ£ãƒƒãƒˆå‡¦ç†**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’å—ã‘å–ã‚Šã€OpenAI ã¸å•åˆã›ã¦è¿”å´
4. **å±¥æ­´ä¿å­˜**    : ã€Œä¿å­˜ã€ãƒœã‚¿ãƒ³ã§ JSON ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
5. **ãƒ¢ãƒ‡ãƒ«å¤‰æ›´**  : ã„ã¤ã§ã‚‚ã€Œãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã€ãƒœã‚¿ãƒ³ã§å†é¸æŠã§ãã‚‹
6. **åœæ­¢ãƒ»å†é–‹**  : â¹ ã§ç”Ÿæˆä¸­æ–­ã€â–¶ ã§ç¶šãã‹ã‚‰å†é–‹
7. **è¨­å®šâš™**      : API Keyï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒã‚¹ã‚¯ï¼‰ã¨ Debug ãƒ¢ãƒ¼ãƒ‰ã®ä¿å­˜ãƒ»åæ˜ 

â€» ãªã‚‹ã¹ã **éã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã‚‚èª­ã‚ã‚‹ã‚ˆã†**ã€å°‚é–€ç”¨èªã‚’å™›ã¿ç •ãã¤ã¤
   ã‚³ãƒ¼ãƒ‰å†…ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤šã‚ã«å…¥ã‚Œã¦ã„ã¾ã™ã€‚
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os, json
from datetime import datetime
from pathlib import Path

import chainlit as cl            # ãƒãƒ£ãƒƒãƒˆ UI ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
from openai import AsyncOpenAI   # OpenAI API éåŒæœŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. ãƒ¦ãƒ¼ã‚¶è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ä¿å­˜ï¼ˆ.env ã¯å‚ç…§ã—ãªã„ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# main.py ã®ã‚ã‚‹å ´æ‰€ã‚’ãƒ™ãƒ¼ã‚¹ã« .chainlit/config.toml ã‚’æŒ‡å®š
CHAINLIT_CONFIG_PATH = Path(__file__).parent / ".chainlit" / "config.toml"
os.environ["CHAINLIT_CONFIG_PATH"] = str(CHAINLIT_CONFIG_PATH)
USER_SETTINGS_PATH = Path(".chainlit/client/user_settings.json")


def load_user_settings() -> dict:
    """JSONâ†’dictã€‚ç„¡ã„å ´åˆã¯ç©º dict"""
    try:
        return json.loads(USER_SETTINGS_PATH.read_text(encoding="utf-8"))
    except Exception:
        return {}

def save_user_settings(data: dict):
    """dictâ†’JSONï¼ˆUTFâ€‘8, ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ 2ï¼‰"""
    USER_SETTINGS_PATH.write_text(
        json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8"
    )

conf = load_user_settings()  # è¨­å®šèª­ã¿è¾¼ã¿

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. èµ·å‹•æ™‚è¨­å®šï¼ˆAPI Key / Debug ãƒ¢ãƒ¼ãƒ‰ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2â€‘A API Key
if key := conf.get("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = key   # OS ç’°å¢ƒå¤‰æ•°ã«å³åæ˜ 

# 2â€‘B Debug ãƒ¢ãƒ¼ãƒ‰
def str2bool(v: str) -> bool:
    return str(v).lower() in ("1", "true", "yes")

DEBUG_MODE: bool = bool(conf.get("DEBUG_MODE", False))

# 2â€‘C API Key ãŒç„¡åŠ¹ãªã‚‰å¼·åˆ¶ Debug
if not os.getenv("OPENAI_API_KEY", "").startswith("sk-"):
    DEBUG_MODE = True

# 2â€‘D OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def get_prefix() -> str:
    return "ğŸ› ï¸ã€ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã€‘\n" if DEBUG_MODE else ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODELS = [
    ("GPTâ€‘3.5 Turbo", "gpt-3.5-turbo"),
    ("GPTâ€‘4 Turbo",   "gpt-4-turbo"),
    ("GPTâ€‘4o",        "gpt-4o"),
]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. å…±é€šã‚¢ã‚¯ã‚·ãƒ§ãƒ³
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def common_actions(show_resume: bool = False):
    base = [
        cl.Action(name="save",      label="ä¿å­˜",          payload={"action": "save"}),
        cl.Action(name="change_model", label="ãƒ¢ãƒ‡ãƒ«å¤‰æ›´", payload={"action": "change_model"}),
        cl.Action(name="cancel",    label="â¹ åœæ­¢",        payload={"action": "cancel"}),
        cl.Action(name="shutdown",  label="ğŸ”´ ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ãƒ»çµ‚äº†",        payload={"action": "shutdown"}),
    ]
    if show_resume:
        base.append(cl.Action(name="resume", label="â–¶ ç¶šã", payload={"action": "resume"}))
    return base

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. ãƒ¢ãƒ‡ãƒ«é¸æŠ UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def show_model_selection():
    await cl.Message(
        content=f"{get_prefix()}ğŸ§  ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
        actions=[
            cl.Action(name="shutdown",  label="ğŸ”´ ãƒ—ãƒ­ã‚»ã‚¹ã‚’åœæ­¢ãƒ»çµ‚äº†", payload={"action": "shutdown"}),
            *[cl.Action(name="select_model", label=label, payload={"model": val})
              for label, val in MODELS]
        ],
    ).send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. OpenAI å‘¼ã³å‡ºã—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def ask_openai(msg: str, history: list[dict], model: str,
                     temperature: float = 0.7, max_tokens: int = 1024):
    if DEBUG_MODE:
        async def dummy():
            for t in ["ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰", "ã“ã‚Œã¯ ", "OpenAI ã‚’ ", "å‘¼ã³å‡ºã—ã¦ ", "ã„ã¾ã›ã‚“ã€‚"]:
                yield type("Chunk", (), {
                    "choices": [type("Choice", (), {
                        "delta": type("Delta", (), {"content": t})()
                    })()]
                })()
        return dummy()

    messages = history + [{"role": "user", "content": msg}]
    return await client.chat.completions.create(
        model=model, messages=messages,
        temperature=temperature, max_tokens=max_tokens, stream=True
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. Chainlit ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@cl.on_chat_start
async def start(): await show_model_selection()

@cl.action_callback("change_model")
async def change_model(_): await show_model_selection()

@cl.action_callback("select_model")
async def model_selected(a: cl.Action):
    cl.user_session.set("selected_model", a.payload["model"])
    await cl.Message(
        content=f"{get_prefix()}âœ… ãƒ¢ãƒ‡ãƒ«ã€Œ{a.payload['model']}ã€ã‚’é¸æŠã—ã¾ã—ãŸã€‚è³ªå•ã‚’ã©ã†ãï¼",
        actions=common_actions(),
    ).send()

@cl.action_callback("cancel")
async def cancel(_):
    cl.user_session.set("cancel_flag", True)
    await cl.Message(content="â¹ ç”Ÿæˆã‚’åœæ­¢ã—ã¾ã™â€¦",
                     actions=common_actions(show_resume=True)).send()

@cl.action_callback("resume")
async def resume(_):
    last = cl.user_session.get("last_user_msg")
    if last:
        await on_message(cl.Message(content="ç¶šãã‹ã‚‰ãŠé¡˜ã„ã—ã¾ã™ã€‚",
                                    author="user", id="resume"), resume=True)

@cl.action_callback("save")
async def save_hist(_):
    hist = cl.user_session.get("chat_history", [])
    if not hist: return
    out = Path("chatlogs"); out.mkdir(exist_ok=True)
    fp = out / f"session_{datetime.now():%Y%m%d_%H%M%S}.json"
    fp.write_text(json.dumps(hist, indent=2, ensure_ascii=False), "utf-8")
    await cl.Message(content="ã‚„ã‚Šå–ã‚Šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚",
                     elements=[cl.File(name=fp.name, path=str(fp), display="inline")]).send()

@cl.action_callback("shutdown")
async def shutdown(_):
    await cl.Message(content="ğŸ”´ ã‚µãƒ¼ãƒãƒ¼ã‚’çµ‚äº†ã—ã¾ã™â€¦").send()
    await cl.sleep(0.1); os._exit(0)

# â˜… è¨­å®šä¿å­˜ï¼ˆAPI Keyï¼‹Debugï¼‰
@cl.action_callback("save_settings")
async def save_settings(a: cl.Action):
    global DEBUG_MODE, client
    payload = a.payload or {}
    conf.update({k:v for k,v in {
        "OPENAI_API_KEY": payload.get("key", "").strip() or conf.get("OPENAI_API_KEY", ""),
        "DEBUG_MODE":     payload.get("debug", DEBUG_MODE)
    }.items() if v not in ("", None)})

    # å³æ™‚åæ˜ 
    if conf.get("OPENAI_API_KEY", "").startswith("sk-"):
        os.environ["OPENAI_API_KEY"] = conf["OPENAI_API_KEY"]
        client = AsyncOpenAI(api_key=conf["OPENAI_API_KEY"])
    else:
        DEBUG_MODE = True
    DEBUG_MODE = bool(conf.get("DEBUG_MODE", False)) or not os.getenv("OPENAI_API_KEY", "").startswith("sk-")

    save_user_settings(conf)
    await cl.Message(content="âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ").send()

# â€•â€•â€• ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ© â€•â€•â€•
@cl.on_message
async def on_message(msg: cl.Message, resume: bool = False):
    cl.user_session.set("cancel_flag", False)
    hist = cl.user_session.get("chat_history", [])
    if not resume:
        hist.append({"role": "user", "content": msg.content})
        cl.user_session.set("last_user_msg", msg.content)

    model = cl.user_session.get("selected_model", "gpt-4o")
    stream_msg = await cl.Message(content="").send()

    try:
        stream = await ask_openai(msg.content, hist, model)
        assistant_text = ""
        async for chunk in stream:
            if cl.user_session.get("cancel_flag"): await stream.aclose(); break
            delta = chunk.choices[0].delta.content
            if delta:
                assistant_text += delta
                stream_msg.content += delta
                await stream_msg.update()
        if not cl.user_session.get("cancel_flag"):
            hist.append({"role": "assistant", "content": assistant_text})

    except Exception as e:
        await cl.Message(content=f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}").send()

    finally:
        cl.user_session.set("chat_history", hist)
        await cl.Message(
            content="âœ… å¿œç­”å®Œäº†ï¼æ¬¡ã®æ“ä½œã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
            actions=common_actions(show_resume=cl.user_session.get("cancel_flag"))
        ).send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
ãƒ»Chainlit å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ       : https://docs.chainlit.io
ãƒ»OpenAI Chat API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹   : https://platform.openai.com/docs/api-reference/chat
"""
