"""
main.py ï¼ Chainlit + OpenAI ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª
=========================================
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒãƒ£ãƒƒãƒˆ UI ãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ã€‚
åˆ©ç”¨è€…ã¯ã€ŒGPTâ€‘3.5 / GPTâ€‘4 / GPTâ€‘4oã€ã‚’é€”ä¸­ã§ã‚‚è‡ªç”±ã«åˆ‡ã‚Šæ›¿ãˆã¦å¯¾è©±ã§ãã¾ã™ã€‚
ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã‚‚å¯èƒ½ã§ã™ã€‚

Chainlit 2.5.5ã®æ©Ÿèƒ½ã‚’æœ€å¤§é™ã«æ´»ç”¨ã—ãŸå®Ÿè£…ã§ã™ã€‚
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import sys
import json
import asyncio
import time
import traceback
from typing import Dict, List, Any, Optional, Tuple, Union

import chainlit as cl

# â–¼ è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import config               # è¨­å®šã¨åˆæœŸåŒ–
import models_utils         # ãƒ¢ãƒ‡ãƒ«é–¢é€£
import history_utils        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ä¿å­˜é–¢é€£
import ui_actions           # UIã‚¢ã‚¯ã‚·ãƒ§ãƒ³é–¢é€£
import file_utils           # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–¢é€£
import error_utils  # ã‚¨ãƒ©ãƒ¼å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. åˆæœŸè¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç’°å¢ƒè¨­å®šã‚’èª­ã¿è¾¼ã‚€
settings = config.setup_environment()

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = models_utils.init_openai_client(settings["OPENAI_API_KEY"])

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°é–¢æ•°
async def handle_error(e: Exception, context: str = "å‡¦ç†ä¸­"):
    """ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é©åˆ‡ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹"""
    error_type = type(e).__name__
    error_message = str(e)
    
    # ãƒ­ã‚°ã«ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’å‡ºåŠ›
    stack_trace = traceback.format_exc()
    print(f"[ERROR] {context}: {error_type}: {error_message}\n{stack_trace}")
    
    # ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸã‚¢ã‚¤ã‚³ãƒ³
    icon = "ã‚¨ãƒ©ãƒ¼"
    
    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡
    message = f"{icon} {context}ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {error_message}"
    
    await cl.Message(
        content=message,
        actions=[
            cl.Action(name="retry", label="å†è©¦è¡Œ", payload={"action": "retry"})
        ]
    ).send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. Chainlit ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@cl.on_chat_start
async def start():
    """ãƒãƒ£ãƒƒãƒˆé–‹å§‹æ™‚ã®å‡¦ç†"""
    try:
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®åˆæœŸåŒ–
        cl.user_session.set("files", {})
        cl.user_session.set("chat_history", [])
        cl.user_session.set("cancel_flag", False)
        cl.user_session.set("partial_response", "")
        cl.user_session.set("selected_model", "gpt-4o")

        
        if not settings["API_KEY_VALID"]:
            # APIã‚­ãƒ¼ãŒãªã„å ´åˆã¯è­¦å‘Šè¡¨ç¤º
            await cl.Message(
                content="**OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ç„¡åŠ¹ã§ã™ï¼**\n"
                        "`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®ã‚ˆã†ã«è¨­å®šã—ã¦ãã ã•ã„ï¼š\n"
                        "`OPENAI_API_KEY=\"sk-xxxx...\"`",
                actions=ui_actions.common_actions(),
            ).send()
            return

        # é€šå¸¸ã®é–‹å§‹å‡¦ç†
        await ui_actions.show_welcome_message(models_utils.MODELS)
    
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®å‡¦ç†
        await handle_error(e, "ãƒãƒ£ãƒƒãƒˆé–‹å§‹å‡¦ç†ä¸­")

@cl.action_callback("change_model")
async def change_model(_):
    """ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        # è©³ç´°æƒ…å ±ä»˜ãã®ãƒ¢ãƒ‡ãƒ«é¸æŠUIã‚’è¡¨ç¤º
        if hasattr(models_utils, "MODEL_INFO") and models_utils.MODEL_INFO:
            await ui_actions.show_model_info_selection(models_utils.MODELS, models_utils.MODEL_INFO)
        else:
            await ui_actions.show_model_selection(models_utils.MODELS, config.get_prefix(settings["DEBUG_MODE"]))
    except Exception as e:
        await handle_error(e, "ãƒ¢ãƒ‡ãƒ«é¸æŠå‡¦ç†ä¸­")

@cl.action_callback("select_model")
async def model_selected(action: cl.Action):
    """ãƒ¢ãƒ‡ãƒ«é¸æŠã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        model = action.payload.get("model")
        if not model:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã«ä¿å­˜
        cl.user_session.set("selected_model", model)
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
        model_label = models_utils.get_model_label(model)
        model_info = None
        
        # MODEL_INFOãŒã‚ã‚Œã°åˆ©ç”¨
        if hasattr(models_utils, "MODEL_INFO") and models_utils.MODEL_INFO:
            model_info = models_utils.MODEL_INFO.get(model, {})
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        content = f"{config.get_prefix(settings['DEBUG_MODE'])}ãƒ¢ãƒ‡ãƒ«ã€Œ{model_label}ã€ã‚’é¸æŠã—ã¾ã—ãŸã€‚\n\n"
        
        if model_info:
            content += (
                f"- **{model_info.get('description', '')}**\n"
                f"- æ–‡è„ˆçª“: {model_info.get('context_window', 'N/A')} ãƒˆãƒ¼ã‚¯ãƒ³\n"
                f"- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {model_info.get('training_data', 'N/A')}\n\n"
            )
        
        content += "è³ªå•ã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼"
        
        await cl.Message(
            content=content,
            actions=ui_actions.common_actions(),
        ).send()
    except Exception as e:
        await handle_error(e, "ãƒ¢ãƒ‡ãƒ«é¸æŠå‡¦ç†ä¸­")

# â˜… ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
@cl.action_callback("upload_file")
async def upload_file_action(_):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        files = await cl.AskFileMessage(
            content="åˆ†æã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
                    "ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: CSV, Excel, ãƒ†ã‚­ã‚¹ãƒˆ, JSON, PDF, ç”»åƒ",
            accept=["text/csv", "application/vnd.ms-excel", 
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
                    "text/plain", "application/json", "application/pdf", 
                    "image/png", "image/jpeg", "image/jpg"],
            max_size_mb=10,
            timeout=180,
        ).send()

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’åˆ‡ã‚Šå‡ºã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å§”è­²
        processed_files = await file_utils.handle_file_upload(files, settings["UPLOADS_DIR"])
        
        # å‡¦ç†ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
        current_files = cl.user_session.get("files", {})
        current_files.update(processed_files)
        cl.user_session.set("files", current_files)
    
    except Exception as e:
        await handle_error(e, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ä¸­")

@cl.action_callback("show_details")
async def show_file_details(action):
    """ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°è¡¨ç¤ºã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        file_name = action.payload.get("file_name")
        if not file_name:
            raise ValueError("ãƒ•ã‚¡ã‚¤ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        files = cl.user_session.get("files", {})
        
        if file_name not in files:
            await cl.Message(content=f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
            return
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’å–å¾—
        file_info = files[file_name]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè©³ç´°è¡¨ç¤º
        if file_info["type"] in ["csv", "excel"]:
            await file_utils.display_dataframe_details(file_info["dataframe"], file_name)
        elif file_info["type"] == "text":
            await cl.Message(
                content=f"### {file_name} ã®å…¨æ–‡:\n```\n{file_info['full_content']}\n```"
            ).send()
        elif file_info["type"] == "json":
            json_str = json.dumps(file_info["content"], indent=2, ensure_ascii=False)
            await cl.Message(
                content=f"### {file_name} ã®å†…å®¹:\n```json\n{json_str}\n```"
            ).send()
        else:
            await cl.Message(content=f"ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®è©³ç´°è¡¨ç¤ºã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“: {file_info['type']}").send()
    
    except Exception as e:
        await handle_error(e, "ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°è¡¨ç¤ºå‡¦ç†ä¸­")

@cl.action_callback("analyze_file")
async def analyze_file(action):
    """ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        file_name = action.payload.get("file_name")
        if not file_name:
            raise ValueError("ãƒ•ã‚¡ã‚¤ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        files = cl.user_session.get("files", {})
        
        if file_name not in files:
            await cl.Message(content=f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
            return
        
        # å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        processing_msg = await ui_actions.show_processing_status(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‚’è©³ç´°ã«åˆ†æã—ã¦ã„ã¾ã™")
        
        file_info = files[file_name]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æ
            if file_info["type"] == "csv" and "dataframe" in file_info:
                # CSVãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                df = file_info["dataframe"]
                csv_str = df.head(20).to_csv(index=False)
                prompt = (
                    f"ä»¥ä¸‹ã®CSVãƒ‡ãƒ¼ã‚¿ï¼ˆã€Œ{file_name}ã€ã®æœ€åˆã®20è¡Œï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                    "åŸºæœ¬çš„ãªçµ±è¨ˆæƒ…å ±ã€ãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘ã€ãŠã‚ˆã³ç‰¹å¾´ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                    f"```\n{csv_str}\n```"
                )
            elif file_info["type"] == "excel" and "dataframe" in file_info:
                # Excelãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                df = file_info["dataframe"]
                excel_str = df.head(20).to_csv(index=False)
                prompt = (
                    f"ä»¥ä¸‹ã®Excelãƒ‡ãƒ¼ã‚¿ï¼ˆã€Œ{file_name}ã€ã®æœ€åˆã®20è¡Œï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                    "åŸºæœ¬çš„ãªçµ±è¨ˆæƒ…å ±ã€ãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘ã€ãŠã‚ˆã³ç‰¹å¾´ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                    f"```\n{excel_str}\n```"
                )
            elif file_info["type"] == "text" and "full_content" in file_info:
                # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                content = file_info["full_content"]
                if len(content) > 5000:
                    content = content[:5000] + "..."  # é•·ã™ãã‚‹å ´åˆã¯çœç•¥
                prompt = (
                    f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®å†…å®¹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                    "ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã€æ§‹é€ ã€æ–‡ä½“ã€ãƒˆãƒ”ãƒƒã‚¯ãªã©ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                    f"```\n{content}\n```"
                )
            elif file_info["type"] == "json" and "content" in file_info:
                # JSONåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                json_str = json.dumps(file_info["content"], indent=2, ensure_ascii=False)
                if len(json_str) > 5000:
                    json_str = json_str[:5000] + "..."  # é•·ã™ãã‚‹å ´åˆã¯çœç•¥
                prompt = (
                    f"ä»¥ä¸‹ã®JSONãƒ‡ãƒ¼ã‚¿ï¼ˆã€Œ{file_name}ã€ï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                    "ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã€ä¸»è¦ãªè¦ç´ ã€ç‰¹å¾´ãªã©ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                    f"```json\n{json_str}\n```"
                )
            elif file_info["type"] == "image":
                # ç”»åƒåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                prompt = f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å†…å®¹ã‚„ç‰¹å¾´ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
            elif file_info["type"] == "pdf":
                # PDFåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                prompt = f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å†…å®¹ã®è¦ç´„ã‚„ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
            else:
                prompt = f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®åˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
            
            # å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ›´æ–°
            processing_msg.content = f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ"
            await processing_msg.update()
            
            # åˆ†æã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡
            msg = cl.Message(content=prompt)
            await on_message(msg)
        
        except Exception as e:
            processing_msg.content = f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
            await processing_msg.update()
            raise e
    
    except Exception as e:
        await handle_error(e, "ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æå‡¦ç†ä¸­")

# â˜… åœæ­¢ãƒœã‚¿ãƒ³
@cl.action_callback("cancel")
async def cancel_stream(_):
    """ç”Ÿæˆåœæ­¢ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        cl.user_session.set("cancel_flag", True)
        
        await cl.Message(
            content="ç”Ÿæˆã‚’åœæ­¢ã—ã¾ã™â€¦", 
            actions=ui_actions.common_actions(show_resume=True)
        ).send()
    except Exception as e:
        await handle_error(e, "ç”Ÿæˆåœæ­¢å‡¦ç†ä¸­")

# â˜… å†é–‹ãƒœã‚¿ãƒ³
@cl.action_callback("resume")
async def resume_stream(_):
    """ç”Ÿæˆå†é–‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        last_user_msg = cl.user_session.get("last_user_msg", "")
        partial_response = cl.user_session.get("partial_response", "")
        
        if not last_user_msg:
            await cl.Message(content="å†é–‹ã§ãã‚‹ä¼šè©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
            return
        
        # éƒ¨åˆ†çš„ãªå¿œç­”ãŒã‚ã‚Œã°è¡¨ç¤º
        if partial_response:
            await cl.Message(
                content=f"**å‰å›ã®é€”ä¸­ã¾ã§ã®å¿œç­”**:\n\n{partial_response}\n\n---\n\nç¶šãã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™..."
            ).send()
        
        # ç¶šãã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        continuation_prompt = (
            f"{last_user_msg}\n\n"
            f"[å‰å›ã®å¿œç­”]:\n{partial_response}\n\n"
            "ç¶šãã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        )
        
        # å†åº¦ ask_openai
        await on_message(cl.Message(content=continuation_prompt, author="user", id="resume"), resume=True)
    
    except Exception as e:
        await handle_error(e, "ç”Ÿæˆå†é–‹å‡¦ç†ä¸­")

# â˜… ä¿å­˜ãƒœã‚¿ãƒ³ï¼ˆTXTãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã¿ï¼‰
@cl.action_callback("save")
async def save_history(_):
    """ä¼šè©±å±¥æ­´ä¿å­˜ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        history = cl.user_session.get("chat_history", [])
        
        if not history:
            await cl.Message(content="ä¿å­˜ã™ã‚‹ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚").send()
            return
        
        # å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        processing_msg = await ui_actions.show_processing_status("ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã—ã¦ã„ã¾ã™")
        
        # TXTå½¢å¼ã§ä¿å­˜
        txt_fp = history_utils.save_chat_history_txt(
            history, 
            settings["CHAT_LOG_DIR"], 
            settings["SESSION_ID"], 
            is_manual=True
        )
        
        if not txt_fp:
            processing_msg.content = "ä¼šè©±å±¥æ­´ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"
            await processing_msg.update()
            return
        
        # å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ›´æ–°
        processing_msg.content = "ä¼šè©±å±¥æ­´ã®ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸ"
        await processing_msg.update()
        
        # ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
        elements = [
            cl.File(
                name=txt_fp.name, 
                path=str(txt_fp), 
                display="inline", 
                mime="text/plain", 
                description="ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼ˆèª­ã¿ã‚„ã™ã„å½¢å¼ï¼‰"
            )
        ]
        
        await cl.Message(
            content=f"ã“ã®ãƒãƒ£ãƒãƒ«ã§ã®ã‚„ã‚Šå–ã‚Šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚\nä¿å­˜å…ˆ: {settings['CHAT_LOG_DIR']}",
            elements=elements
        ).send()
    
    except Exception as e:
        await handle_error(e, "ä¼šè©±å±¥æ­´ä¿å­˜å‡¦ç†ä¸­")

# â˜… ãƒ—ãƒ­ã‚»ã‚¹å®Œå…¨çµ‚äº†ãƒœã‚¿ãƒ³
@cl.action_callback("shutdown")
async def shutdown_app(_):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    await cl.Message(content="ã‚µãƒ¼ãƒãƒ¼ã‚’çµ‚äº†ã—ã¾ã™â€¦").send()
    await cl.sleep(0.5)  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡çŒ¶äºˆ
    os._exit(0)          # å³ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ï¼ˆSystemExitã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çµ‚äº†ï¼‰

# â˜… å†è©¦è¡Œãƒœã‚¿ãƒ³
@cl.action_callback("retry")
async def retry_action(action):
    """å†è©¦è¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        # å‰å›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦å†é€ä¿¡
        last_user_msg = cl.user_session.get("last_user_msg", "")
        if not last_user_msg:
            await cl.Message(content="å†è©¦è¡Œã™ã‚‹ä¼šè©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
            return
        
        # å†è©¦è¡Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        await cl.Message(content="ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å†è©¦è¡Œã—ã¦ã„ã¾ã™...").send()
        
        # å‰å›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å†é€ä¿¡
        await on_message(cl.Message(content=last_user_msg, author="user", id="retry"))
    
    except Exception as e:
        await handle_error(e, "å†è©¦è¡Œå‡¦ç†ä¸­")

# ãƒ¡ã‚¤ãƒ³ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©
# main.py - on_messageé–¢æ•°ã®ä¿®æ­£
@cl.on_message
async def on_message(msg: cl.Message):
    """ãƒ¡ã‚¤ãƒ³ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
    try:
        # äº‹å‰çŠ¶æ…‹ã®ãƒªã‚»ãƒƒãƒˆã¨å±¥æ­´å‡¦ç†
        cl.user_session.set("cancel_flag", False)
        history = cl.user_session.get("chat_history", [])
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ï¼‰
        sanitized_content = config.sanitize_input(msg.content)
        
        # å±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        history.append({"role": "user", "content": sanitized_content})
        cl.user_session.set("last_user_msg", sanitized_content)
        cl.user_session.set("chat_history", history)  # é‡è¦: ã“ã“ã§å±¥æ­´ã‚’ä¿å­˜

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—
        model = cl.user_session.get("selected_model", "gpt-4o")
        
        # å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åˆæœŸåŒ–
        stream_msg = cl.Message(content="")
        await stream_msg.send()

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãŒãªã„ã‹ãƒã‚§ãƒƒã‚¯
            files = cl.user_session.get("files", {})
            message_content = sanitized_content
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãŒã‚ã‚‹å ´åˆã€é–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½åŠ 
            message_content = file_utils.get_file_reference_content(message_content, files)
            
            # â˜…é‡è¦ãªä¿®æ­£: APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
            if not settings["API_KEY_VALID"]:
                stream_msg.content = "**OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ç„¡åŠ¹ã§ã™ã€‚** .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                await stream_msg.update()
                return  # æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ã§å‡¦ç†ã‚’çµ‚äº†
            
            # â˜…é‡è¦ãªä¿®æ­£: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãAPIå‘¼ã³å‡ºã—
            try:
                # OpenAI APIå‘¼ã³å‡ºã—å‡¦ç†ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
                api_task = asyncio.create_task(models_utils.ask_openai(
                    client, 
                    message_content, 
                    history, 
                    model, 
                    debug_mode=settings["DEBUG_MODE"]
                ))
                
                # 30ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’è¨­å®š
                stream = await asyncio.wait_for(api_task, timeout=30.0)
            except asyncio.TimeoutError:
                stream_msg.content = "APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦è©¦ã™ã‹ã€è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
                await stream_msg.update()
                return  # æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ã§å‡¦ç†ã‚’çµ‚äº†
            
            # å¿œç­”ã‚’æ§‹ç¯‰
            assistant_text = ""
            
            # â˜…é‡è¦ãªä¿®æ­£: æ˜ç¤ºçš„ã«å‡¦ç†å®Œäº†ã‚’ç¤ºã™å¤‰æ•°
            processing_completed = False
            
            try:
                async for chunk in stream:
                    # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
                    if cl.user_session.get("cancel_flag", False):
                        await stream.aclose()
                        cl.user_session.set("partial_response", assistant_text)
                        break
                    
                    # ãƒãƒ£ãƒ³ã‚¯å†…å®¹ã®å–å¾—ã¨è¿½åŠ 
                    content = chunk.choices[0].delta.content
                    if content:
                        assistant_text += content
                        stream_msg.content = assistant_text
                        await stream_msg.update()
                
                # æ˜ç¤ºçš„ã«å‡¦ç†å®Œäº†ã‚’è¨­å®š
                processing_completed = True
            
            except Exception as e:
                stream_msg.content = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                await stream_msg.update()
                print(f"ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
                traceback.print_exc()
            
            # å‡¦ç†ãŒå®Œäº†ã—ãŸã‚‰ã®ã¿å±¥æ­´ã«è¿½åŠ 
            if processing_completed and not cl.user_session.get("cancel_flag", False):
                # å±¥æ­´ã«å¿œç­”ã‚’è¿½åŠ 
                history.append({"role": "assistant", "content": assistant_text})
                cl.user_session.set("chat_history", history)
                cl.user_session.set("partial_response", "")
                
                # æ˜ç¤ºçš„ã«å‡¦ç†å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                await cl.Message(content="âœ… å¿œç­”ãŒå®Œäº†ã—ã¾ã—ãŸ").send()
            
        except Exception as e:
            error_message = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            stream_msg.content = error_message
            await stream_msg.update()
            print(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {error_message}")
            traceback.print_exc()

    except Exception as e:
        print(f"å…¨ä½“ã‚¨ãƒ©ãƒ¼: {str(e)}")
        traceback.print_exc()
        await cl.Message(content=f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}").send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
ãƒ»Chainlit å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ       : https://docs.chainlit.io
ãƒ»OpenAI Chat API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹   : https://platform.openai.com/docs/api-reference/chat
ãƒ»python-dotenv ä½¿ã„æ–¹            : https://pypi.org/project/python-dotenv/
"""