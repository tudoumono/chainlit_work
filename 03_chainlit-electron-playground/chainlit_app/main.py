"""
main.py ï¼ Chainlit + OpenAI ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª
=========================================
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒãƒ£ãƒƒãƒˆ UI ãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ã€‚
åˆ©ç”¨è€…ã¯ã€ŒGPTâ€‘3.5 / GPTâ€‘4 / GPTâ€‘4oã€ã‚’é€”ä¸­ã§ã‚‚è‡ªç”±ã«åˆ‡ã‚Šæ›¿ãˆã¦å¯¾è©±ã§ãã¾ã™ã€‚
ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã‚‚å¯èƒ½ã§ã™ã€‚

--------------------------------------------------------------------------
ğŸ’¡ "ã–ã£ãã‚Šå…¨ä½“åƒ"
--------------------------------------------------------------------------
1. **åˆæœŸåŒ–**      : ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ã€OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
2. **ãƒ¢ãƒ‡ãƒ«é¸æŠUI**: èµ·å‹•æ™‚ã«ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºï¼ˆ`show_model_selection()`ï¼‰
3. **ãƒãƒ£ãƒƒãƒˆå‡¦ç†**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’å—ã‘å–ã‚Šã€OpenAI ã¸å•åˆã›ã¦è¿”å´
4. **å±¥æ­´ä¿å­˜**    : ã€Œä¿å­˜ã€ãƒœã‚¿ãƒ³ã§ TXT ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ & è‡ªå‹•TXTä¿å­˜æ©Ÿèƒ½è¿½åŠ 
5. **ãƒ¢ãƒ‡ãƒ«å¤‰æ›´**  : ã„ã¤ã§ã‚‚ã€Œãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã€ãƒœã‚¿ãƒ³ã§å†é¸æŠã§ãã‚‹
6. **åœæ­¢ãƒ»å†é–‹**  : â¹ ã§ç”Ÿæˆä¸­æ–­ã€â–¶ ã§ç¶šãã‹ã‚‰å†é–‹
7. **ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ**: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã§æ§˜ã€…ãªãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢ã™ã‚‹åˆ†æãŒå¯èƒ½
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import sys
import json
import asyncio
import time
import traceback
from typing import Dict, List, Any, Optional, Tuple, Union

import chainlit as cl

# â–¼ è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import config               # è¨­å®šã¨åˆæœŸåŒ–
import models_utils         # ãƒ¢ãƒ‡ãƒ«é–¢é€£
import history_utils        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ä¿å­˜é–¢é€£
import ui_actions           # UIã‚¢ã‚¯ã‚·ãƒ§ãƒ³é–¢é€£
import file_utils           # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–¢é€£
import error_utils          # ã‚¨ãƒ©ãƒ¼å‡¦ç†é–¢é€£ï¼ˆæ–°è¦è¿½åŠ ï¼‰

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. åˆæœŸè¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç’°å¢ƒè¨­å®šã‚’èª­ã¿è¾¼ã‚€
settings = config.setup_environment()

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = models_utils.init_openai_client(settings["OPENAI_API_KEY"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. Chainlit ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@cl.on_chat_start
async def start():
    """ãƒãƒ£ãƒƒãƒˆé–‹å§‹æ™‚ã®å‡¦ç†"""
    try:
        # ä¸¦åˆ—å‡¦ç†ã§åˆæœŸåŒ–
        tasks = [
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®åˆæœŸåŒ–
            init_session(),
            
            # ã‚¢ãƒã‚¿ãƒ¼ã®è¨­å®š
            setup_avatars(),
            
            # APIç¢ºèª
            check_api_status()
        ]
        
        # ä¸¦åˆ—å®Ÿè¡Œ
        await asyncio.gather(*tasks)
        
        if not settings["API_KEY_VALID"]:
            # APIã‚­ãƒ¼ãŒãªã„å ´åˆã¯è­¦å‘Šè¡¨ç¤º
            await cl.Message(
                content="âŒ **OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ã‹ç„¡åŠ¹ã§ã™ï¼**\n"
                        "`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®ã‚ˆã†ã«è¨­å®šã—ã¦ãã ã•ã„ï¼š\n"
                        "`OPENAI_API_KEY=\"sk-xxxx...\"`",
                actions=ui_actions.common_actions(),
                tooltip="APIã‚­ãƒ¼ã‚¨ãƒ©ãƒ¼"
            ).send()
            return

        # é€šå¸¸ã®é–‹å§‹å‡¦ç†
        await ui_actions.show_welcome_message(models_utils.MODELS)
    
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®å‡¦ç†
        await error_utils.handle_error(e, "ãƒãƒ£ãƒƒãƒˆé–‹å§‹å‡¦ç†ä¸­")

async def init_session():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®åˆæœŸåŒ–"""
    # å‹ä»˜ãã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®è¨­å®š
    cl.user_session.set_typed("files", {}, Dict[str, Dict[str, Any]])
    cl.user_session.set_typed("chat_history", [], List[Dict[str, str]])
    cl.user_session.set_typed("cancel_flag", False, bool)
    cl.user_session.set_typed("partial_response", "", str)
    cl.user_session.set_typed("selected_model", "gpt-4o", str)

async def setup_avatars():
    """ã‚¢ãƒã‚¿ãƒ¼ã®è¨­å®š"""
    # ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒã‚¿ãƒ¼ã®è¨­å®š
    await cl.Avatar(
        name="assistant",
        url="https://avatars.githubusercontent.com/u/128686189?v=4"
    ).send()
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ãƒã‚¿ãƒ¼ã®è¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    await cl.Avatar(
        name="user",
        url="https://ui-avatars.com/api/?name=U&background=random"
    ).send()

async def check_api_status():
    """APIçŠ¶æ…‹ã®ç¢ºèª"""
    if not client:
        print("[WARNING] OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    try:
        # è»½é‡ãªAPIå‘¼ã³å‡ºã—ã§ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèªï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if settings["DEBUG_MODE"]:
            print("[DEBUG] APIæ¥ç¶šçŠ¶æ…‹ã®ç¢ºèªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼‰")
    except Exception as e:
        print(f"[WARNING] APIæ¥ç¶šç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")

@cl.action_callback("change_model")
async def change_model(_):
    """ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        await models_utils.show_model_selection_with_info()
    except Exception as e:
        await error_utils.handle_error(e, "ãƒ¢ãƒ‡ãƒ«é¸æŠå‡¦ç†ä¸­")

@cl.action_callback("select_model")
async def model_selected(action: cl.Action):
    """ãƒ¢ãƒ‡ãƒ«é¸æŠã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        model = action.payload.get("model")
        if not model:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # å‹ä»˜ãã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã«ä¿å­˜
        cl.user_session.set_typed("selected_model", model, str)
        
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
        model_label = models_utils.get_model_label(model)
        model_info = models_utils.get_model_info(model)
        
        # é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®è¡¨ç¤º
        await cl.Message(
            content=f"{config.get_prefix(settings['DEBUG_MODE'])}âœ… ãƒ¢ãƒ‡ãƒ«ã€Œ{model_label}ã€ã‚’é¸æŠã—ã¾ã—ãŸã€‚\n\n"
                    f"- **{model_info['description']}**\n"
                    f"- æ–‡è„ˆçª“: {model_info['context_window']} ãƒˆãƒ¼ã‚¯ãƒ³\n"
                    f"- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {model_info['training_data']}\n\n"
                    "è³ªå•ã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼",
            actions=ui_actions.common_actions(),
            tooltip=f"ãƒ¢ãƒ‡ãƒ«: {model} - {model_info['description']}"
        ).send()
    except Exception as e:
        await error_utils.handle_error(e, "ãƒ¢ãƒ‡ãƒ«é¸æŠå‡¦ç†ä¸­")

# â˜… ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
@cl.action_callback("upload_file")
async def upload_file_action(_):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        files = await cl.AskFileMessage(
            content="åˆ†æã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
                    "ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: CSV, Excel, ãƒ†ã‚­ã‚¹ãƒˆ, JSON, PDF, ç”»åƒ",
            accept=["text/csv", "application/vnd.ms-excel", 
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
                    "text/plain", "application/json", "application/pdf", 
                    "image/png", "image/jpeg", "image/jpg"],
            max_size_mb=10,
            timeout=180,
            tooltip="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: CSV, Excel, ãƒ†ã‚­ã‚¹ãƒˆ, JSON, PDF, ç”»åƒ"
        ).send()

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’åˆ‡ã‚Šå‡ºã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å§”è­²
        processed_files = await file_utils.handle_file_upload(files, settings["UPLOADS_DIR"])
        
        # å‡¦ç†ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆå‹ä»˜ãï¼‰
        current_files = cl.user_session.get_typed("files", Dict[str, Dict[str, Any]], {})
        current_files.update(processed_files)
        cl.user_session.set_typed("files", current_files, Dict[str, Dict[str, Any]])
    
    except Exception as e:
        await error_utils.handle_error(e, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ä¸­")

@cl.action_callback("show_details")
async def show_file_details(action):
    """ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°è¡¨ç¤ºã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        file_name = action.payload.get("file_name")
        if not file_name:
            raise ValueError("ãƒ•ã‚¡ã‚¤ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        files = cl.user_session.get_typed("files", Dict[str, Dict[str, Any]], {})
        
        if file_name not in files:
            await cl.Message(content=f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
            return
        
        file_info = files[file_name]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè©³ç´°è¡¨ç¤º
        if file_info["type"] in ["csv", "excel"]:
            # è©³ç´°åˆ†æç”¨ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Œå…¨å‡¦ç†
            file_info = await file_utils.analyze_file_safely(file_name, files)
            if file_info and "dataframe" in file_info:
                await file_utils.display_dataframe_details(file_info["dataframe"], file_name)
            else:
                await cl.Message(content=f"ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã®è©³ç´°è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚").send()
                
        elif file_info["type"] == "text":
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°è¡¨ç¤º
            file_info = await file_utils.analyze_file_safely(file_name, files)
            if file_info and "full_content" in file_info:
                await cl.Message(
                    content=f"### {file_name} ã®å…¨æ–‡:\n```\n{file_info['full_content']}\n```",
                    tooltip=f"ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«: {file_name}"
                ).send()
            else:
                await cl.Message(content=f"ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã®è©³ç´°è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚").send()
                
        elif file_info["type"] == "json":
            # JSONãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°è¡¨ç¤º
            file_info = await file_utils.analyze_file_safely(file_name, files)
            if file_info and "content" in file_info:
                json_str = json.dumps(file_info["content"], indent=2, ensure_ascii=False)
                await cl.Message(
                    content=f"### {file_name} ã®å†…å®¹:\n```json\n{json_str}\n```",
                    tooltip=f"JSONãƒ•ã‚¡ã‚¤ãƒ«: {file_name}"
                ).send()
            else:
                await cl.Message(content=f"ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ã®è©³ç´°è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚").send()
                
        else:
            await cl.Message(
                content=f"ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®è©³ç´°è¡¨ç¤ºã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“: {file_info['type']}",
                tooltip="æœªã‚µãƒãƒ¼ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼"
            ).send()
    
    except Exception as e:
        await error_utils.handle_error(e, "ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°è¡¨ç¤ºå‡¦ç†ä¸­")

@cl.action_callback("analyze_file")
async def analyze_file(action):
    """ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        file_name = action.payload.get("file_name")
        if not file_name:
            raise ValueError("ãƒ•ã‚¡ã‚¤ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        files = cl.user_session.get_typed("files", Dict[str, Dict[str, Any]], {})
        
        if file_name not in files:
            await cl.Message(content=f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
            return
        
        # å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        processing_msg = await ui_actions.show_processing_status(f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‚’è©³ç´°ã«åˆ†æã—ã¦ã„ã¾ã™")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°åˆ†æ
        file_info = await file_utils.analyze_file_safely(file_name, files)
        if not file_info:
            processing_msg.content = f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ"
            await processing_msg.update()
            return
        
        # å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ›´æ–°
        processing_msg.content = f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ"
        await processing_msg.update()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†
        if file_info["type"] == "csv" and "dataframe" in file_info:
            # CSVãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            df = file_info["dataframe"]
            csv_str = df.head(20).to_csv(index=False)
            prompt = (
                f"ä»¥ä¸‹ã®CSVãƒ‡ãƒ¼ã‚¿ï¼ˆã€Œ{file_name}ã€ã®æœ€åˆã®20è¡Œï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                "åŸºæœ¬çš„ãªçµ±è¨ˆæƒ…å ±ã€ãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘ã€ãŠã‚ˆã³ç‰¹å¾´ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                f"```\n{csv_str}\n```"
            )
        elif file_info["type"] == "excel" and "dataframe" in file_info:
            # Excelãƒ‡ãƒ¼ã‚¿åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            df = file_info["dataframe"]
            excel_str = df.head(20).to_csv(index=False)
            prompt = (
                f"ä»¥ä¸‹ã®Excelãƒ‡ãƒ¼ã‚¿ï¼ˆã€Œ{file_name}ã€ã®æœ€åˆã®20è¡Œï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                "åŸºæœ¬çš„ãªçµ±è¨ˆæƒ…å ±ã€ãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘ã€ãŠã‚ˆã³ç‰¹å¾´ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                f"```\n{excel_str}\n```"
            )
        elif file_info["type"] == "text" and "full_content" in file_info:
            # ãƒ†ã‚­ã‚¹ãƒˆåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            content = file_info["full_content"]
            if len(content) > 5000:
                content = content[:5000] + "..."  # é•·ã™ãã‚‹å ´åˆã¯çœç•¥
            prompt = (
                f"ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®å†…å®¹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                "ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã€æ§‹é€ ã€æ–‡ä½“ã€ãƒˆãƒ”ãƒƒã‚¯ãªã©ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                f"```\n{content}\n```"
            )
        elif file_info["type"] == "json" and "content" in file_info:
            # JSONåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            json_str = json.dumps(file_info["content"], indent=2, ensure_ascii=False)
            if len(json_str) > 5000:
                json_str = json_str[:5000] + "..."  # é•·ã™ãã‚‹å ´åˆã¯çœç•¥
            prompt = (
                f"ä»¥ä¸‹ã®JSONãƒ‡ãƒ¼ã‚¿ï¼ˆã€Œ{file_name}ã€ï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                "ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã€ä¸»è¦ãªè¦ç´ ã€ç‰¹å¾´ãªã©ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                f"```json\n{json_str}\n```"
            )
        elif file_info["type"] == "image":
            # ç”»åƒåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            prompt = f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å†…å®¹ã‚„ç‰¹å¾´ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        elif file_info["type"] == "pdf":
            # PDFåˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            prompt = f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å†…å®¹ã®è¦ç´„ã‚„ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        else:
            prompt = f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®åˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        
        # åˆ†æã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡
        msg = cl.Message(content=prompt)
        await on_message(msg)
    
    except Exception as e:
        await error_utils.handle_error(e, "ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æå‡¦ç†ä¸­")

# â˜… åœæ­¢ãƒœã‚¿ãƒ³
@cl.action_callback("cancel")
async def cancel_stream(_):
    """ç”Ÿæˆåœæ­¢ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        # å‹ä»˜ãã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã‚’ä½¿ç”¨
        cl.user_session.set_typed("cancel_flag", True, bool)
        
        await cl.Message(
            content="â¹ ç”Ÿæˆã‚’åœæ­¢ã—ã¾ã™â€¦", 
            actions=ui_actions.common_actions(show_resume=True),
            tooltip="ç”ŸæˆãŒåœæ­¢ã•ã‚Œã¾ã—ãŸ"
        ).send()
    except Exception as e:
        await error_utils.handle_error(e, "ç”Ÿæˆåœæ­¢å‡¦ç†ä¸­")

# â˜… å†é–‹ãƒœã‚¿ãƒ³
@cl.action_callback("resume")
async def resume_stream(_):
    """ç”Ÿæˆå†é–‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        # å‹ä»˜ãã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã‚’ä½¿ç”¨
        last_user_msg = cl.user_session.get_typed("last_user_msg", str, "")
        partial_response = cl.user_session.get_typed("partial_response", str, "")
        
        if not last_user_msg:
            await cl.Message(
                content="å†é–‹ã§ãã‚‹ä¼šè©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚", 
                tooltip="å‰ã®ä¼šè©±æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“"
            ).send()
            return
        
        # éƒ¨åˆ†çš„ãªå¿œç­”ãŒã‚ã‚Œã°è¡¨ç¤º
        if partial_response:
            await cl.Message(
                content=f"**å‰å›ã®é€”ä¸­ã¾ã§ã®å¿œç­”**:\n\n{partial_response}\n\n---\n\nç¶šãã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...",
                tooltip="å‰å›ã®éƒ¨åˆ†å¿œç­”"
            ).send()
        
        # ç¶šãã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        continuation_prompt = (
            f"{last_user_msg}\n\n"
            f"[å‰å›ã®å¿œç­”]:\n{partial_response}\n\n"
            "ç¶šãã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"
        )
        
        # ã€Œç¶šãã‹ã‚‰ãŠé¡˜ã„ã—ã¾ã™ã€ã‚’è¿½åŠ ã—ã¦å†åº¦ ask_openai
        await on_message(cl.Message(content=continuation_prompt, author="user", id="resume"), resume=True)
    
    except Exception as e:
        await error_utils.handle_error(e, "ç”Ÿæˆå†é–‹å‡¦ç†ä¸­")

# â˜… ä¿å­˜ãƒœã‚¿ãƒ³ï¼ˆTXTãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã¿ï¼‰
@cl.action_callback("save")
async def save_history(_):
    """ä¼šè©±å±¥æ­´ä¿å­˜ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        # å‹ä»˜ãã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã‚’ä½¿ç”¨
        history = cl.user_session.get_typed("chat_history", List[Dict[str, str]], [])
        
        if not history:
            await cl.Message(
                content="ä¿å­˜ã™ã‚‹ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚", 
                tooltip="ä¼šè©±å±¥æ­´ãªã—"
            ).send()
            return
        
        # å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
        processing_msg = await ui_actions.show_processing_status("ä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã—ã¦ã„ã¾ã™")
        
        # TXTå½¢å¼ã§ä¿å­˜
        txt_fp = history_utils.save_chat_history_txt(
            history, 
            settings["CHAT_LOG_DIR"], 
            settings["SESSION_ID"], 
            is_manual=True
        )
        
        if not txt_fp:
            processing_msg.content = "âš ï¸ ä¼šè©±å±¥æ­´ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ"
            await processing_msg.update()
            return
        
        # å‡¦ç†ä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ›´æ–°
        processing_msg.content = "âœ… ä¼šè©±å±¥æ­´ã®ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸ"
        await processing_msg.update()
        
        # ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
        elements = [
            cl.File(
                name=txt_fp.name, 
                path=str(txt_fp), 
                display="inline", 
                mime="text/plain", 
                description="ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼ˆèª­ã¿ã‚„ã™ã„å½¢å¼ï¼‰"
            )
        ]
        
        await cl.Message(
            content=f"ã“ã®ãƒãƒ£ãƒãƒ«ã§ã®ã‚„ã‚Šå–ã‚Šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚\nä¿å­˜å…ˆ: {settings['CHAT_LOG_DIR']}",
            elements=elements,
            tooltip="ä¿å­˜ã•ã‚ŒãŸä¼šè©±å±¥æ­´"
        ).send()
    
    except Exception as e:
        await error_utils.handle_error(e, "ä¼šè©±å±¥æ­´ä¿å­˜å‡¦ç†ä¸­")

# â˜… ãƒ—ãƒ­ã‚»ã‚¹å®Œå…¨çµ‚äº†ãƒœã‚¿ãƒ³
@cl.action_callback("shutdown")
async def shutdown_app(_):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    await cl.Message(
        content="ğŸ”´ ã‚µãƒ¼ãƒãƒ¼ã‚’çµ‚äº†ã—ã¾ã™â€¦",
        tooltip="ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†"
    ).send()
    await cl.sleep(0.5)  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡çŒ¶äºˆ
    os._exit(0)          # å³ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ï¼ˆSystemExitã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çµ‚äº†ï¼‰

# â˜… å†è©¦è¡Œãƒœã‚¿ãƒ³
@cl.action_callback("retry")
async def retry_action(action):
    """å†è©¦è¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    try:
        # å‰å›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦å†é€ä¿¡
        last_user_msg = cl.user_session.get_typed("last_user_msg", str, "")
        if not last_user_msg:
            await cl.Message(content="å†è©¦è¡Œã™ã‚‹ä¼šè©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
            return
        
        # å†è©¦è¡Œãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        await cl.Message(content="ğŸ”„ ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å†è©¦è¡Œã—ã¦ã„ã¾ã™...").send()
        
        # å‰å›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å†é€ä¿¡
        await on_message(cl.Message(content=last_user_msg, author="user", id="retry"))
    
    except Exception as e:
        await error_utils.handle_error(e, "å†è©¦è¡Œå‡¦ç†ä¸­")

# ãƒ¡ã‚¤ãƒ³ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©
@cl.on_message
async def on_message(msg: cl.Message, resume: bool = False):
    """ãƒ¡ã‚¤ãƒ³ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©"""
    try:
        # äº‹å‰çŠ¶æ…‹ã®ãƒªã‚»ãƒƒãƒˆã¨å±¥æ­´å‡¦ç†
        cl.user_session.set_typed("cancel_flag", False, bool)
        history = cl.user_session.get_typed("chat_history", List[Dict[str, str]], [])
        
        if not resume:
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ï¼‰
            sanitized_content = config.sanitize_input(msg.content)
            
            # å±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            history.append({"role": "user", "content": sanitized_content})
            cl.user_session.set_typed("last_user_msg", sanitized_content, str)

        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—
        model = cl.user_session.get_typed("selected_model", str, "gpt-4o")
        model_info = models_utils.get_model_info(model)
        
        # å¿œç­”ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®åˆæœŸåŒ–ï¼ˆãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—ä»˜ãï¼‰
        stream_msg = cl.Message(
            content="",
            tooltip=f"ãƒ¢ãƒ‡ãƒ«: {model} - {model_info['description']}"
        )
        await stream_msg.send()

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãŒãªã„ã‹ãƒã‚§ãƒƒã‚¯
            files = cl.user_session.get_typed("files", Dict[str, Dict[str, Any]], {})
            message_content = msg.content
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãŒã‚ã‚‹å ´åˆã€é–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½åŠ 
            message_content = file_utils.get_file_reference_content(message_content, files)
            
            # OpenAI APIå‘¼ã³å‡ºã—
            stream = await models_utils.ask_openai(
                client, 
                message_content, 
                history, 
                model, 
                debug_mode=settings["DEBUG_MODE"]
            )
            
            # å¿œç­”ã‚’æ§‹ç¯‰
            assistant_text = ""
            token_count = 0
            start_time = time.time()

            async for chunk in stream:
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
                if cl.user_session.get_typed("cancel_flag", bool, False):
                    # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’æ­£ã—ãé–‰ã˜ã‚‹
                    await stream.aclose()
                    
                    # éƒ¨åˆ†çš„ãªå¿œç­”ã‚’ä¿å­˜
                    cl.user_session.set_typed("partial_response", assistant_text, str)
                    break
                
                # ãƒãƒ£ãƒ³ã‚¯å†…å®¹ã®å–å¾—ã¨è¿½åŠ 
                content = chunk.choices[0].delta.content
                if content:
                    assistant_text += content
                    token_count += 1  # æ¦‚ç®—
                    stream_msg.content = assistant_text
                    
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°æ›´æ–°
                    if hasattr(chunk, 'metadata') and chunk.metadata:
                        elapsed_ms = chunk.metadata.get("elapsed_ms", 0)
                        stream_msg.tooltip = (
                            f"ãƒ¢ãƒ‡ãƒ«: {model} - {token_count}ãƒˆãƒ¼ã‚¯ãƒ³ - {elapsed_ms}ms"
                        )
                    
                    await stream_msg.update()

            # å¿œç­”å®Œäº†æ™‚ã®å‡¦ç†
            if not cl.user_session.get_typed("cancel_flag", bool, False):
                # å‡¦ç†æ™‚é–“ã®è¨ˆç®—
                total_time = round((time.time() - start_time) * 1000)
                
                # å±¥æ­´ã«å¿œç­”ã‚’è¿½åŠ 
                history.append({"role": "assistant", "content": assistant_text})
                cl.user_session.set_typed("chat_history", history, List[Dict[str, str]])
                
                # éƒ¨åˆ†çš„ãªå¿œç­”ã‚’ã‚¯ãƒªã‚¢
                cl.user_session.set_typed("partial_response", "", str)
                
                # æœ€çµ‚çš„ãªãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—æ›´æ–°
                stream_msg.tooltip = (
                    f"ãƒ¢ãƒ‡ãƒ«: {model} - {token_count}ãƒˆãƒ¼ã‚¯ãƒ³ - {total_time}mså®Œäº†"
                )
                await stream_msg.update()
                
                # è‡ªå‹•ä¿å­˜
                history_utils.save_chat_history_txt(
                    history, 
                    settings["CHAT_LOG_DIR"], 
                    settings["SESSION_ID"]
                )
                
                # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
                await ui_actions.show_action_buttons()

        except Exception as e:
            await error_utils.handle_error(e, "OpenAI APIå‘¼ã³å‡ºã—ä¸­")

    except Exception as e:
        await error_utils.handle_error(e, "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ä¸­")
    
    finally:
        # æœ€çµ‚çš„ã«çŠ¶æ…‹ã‚’ä¿å­˜
        cl.user_session.set_typed("chat_history", history, List[Dict[str, str]])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
ãƒ»Chainlit å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ       : https://docs.chainlit.io
ãƒ»OpenAI Chat API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹   : https://platform.openai.com/docs/api-reference/chat
ãƒ»python-dotenv ä½¿ã„æ–¹            : https://pypi.org/project/python-dotenv/
"""