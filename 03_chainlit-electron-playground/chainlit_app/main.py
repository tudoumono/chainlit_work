"""
main.py ï¼ Chainlit + OpenAI ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª
=========================================
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒãƒ£ãƒƒãƒˆ UI ãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ã€‚
åˆ©ç”¨è€…ã¯ã€ŒGPTâ€‘3.5 / GPTâ€‘4 / GPTâ€‘4oã€ã‚’é€”ä¸­ã§ã‚‚è‡ªç”±ã«åˆ‡ã‚Šæ›¿ãˆã¦å¯¾è©±ã§ãã¾ã™ã€‚
ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ãƒ‡ãƒ¼ã‚¿ã®åˆ†æã‚‚å¯èƒ½ã§ã™ã€‚

--------------------------------------------------------------------------
ğŸ’¡ "ã–ã£ãã‚Šå…¨ä½“åƒ"
--------------------------------------------------------------------------
1. **åˆæœŸåŒ–**      : ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ã€OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
2. **ãƒ¢ãƒ‡ãƒ«é¸æŠUI**: èµ·å‹•æ™‚ã«ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºï¼ˆ`show_model_selection()`ï¼‰
3. **ãƒãƒ£ãƒƒãƒˆå‡¦ç†**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’å—ã‘å–ã‚Šã€OpenAI ã¸å•åˆã›ã¦è¿”å´
4. **å±¥æ­´ä¿å­˜**    : ã€Œä¿å­˜ã€ãƒœã‚¿ãƒ³ã§ TXT ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ & è‡ªå‹•TXTä¿å­˜æ©Ÿèƒ½è¿½åŠ 
5. **ãƒ¢ãƒ‡ãƒ«å¤‰æ›´**  : ã„ã¤ã§ã‚‚ã€Œãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã€ãƒœã‚¿ãƒ³ã§å†é¸æŠã§ãã‚‹
6. **åœæ­¢ãƒ»å†é–‹**  : â¹ ã§ç”Ÿæˆä¸­æ–­ã€â–¶ ã§ç¶šãã‹ã‚‰å†é–‹
7. **ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ**: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã§æ§˜ã€…ãªãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢ã™ã‚‹åˆ†æãŒå¯èƒ½
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import sys
import json
import chainlit as cl

# â–¼ è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import config               # è¨­å®šã¨åˆæœŸåŒ–
import models_utils         # ãƒ¢ãƒ‡ãƒ«é–¢é€£
import history_utils        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ä¿å­˜é–¢é€£
import ui_actions           # UIã‚¢ã‚¯ã‚·ãƒ§ãƒ³é–¢é€£
import file_utils           # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–¢é€£

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. åˆæœŸè¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ç’°å¢ƒè¨­å®šã‚’èª­ã¿è¾¼ã‚€
settings = config.setup_environment()

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = models_utils.init_openai_client(settings["OPENAI_API_KEY"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. Chainlit ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@cl.on_chat_start
async def start():
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®åˆæœŸåŒ–
    cl.user_session.set("files", {})
    
    if not settings["OPENAI_API_KEY"]:
        # APIã‚­ãƒ¼ãŒãªã„å ´åˆã¯è­¦å‘Šè¡¨ç¤º
        await cl.Message(
            content="âŒ **OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼**\n"
                    "`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®ã‚ˆã†ã«è¨­å®šã—ã¦ãã ã•ã„ï¼š\n"
                    "`OPENAI_API_KEY=\"sk-xxxx...\"`",
            actions=ui_actions.common_actions(),
        ).send()
        return

    # é€šå¸¸ã®é–‹å§‹å‡¦ç†
    await ui_actions.show_welcome_message(models_utils.MODELS)

@cl.action_callback("change_model")
async def change_model(_):
    await ui_actions.show_model_selection(models_utils.MODELS, config.get_prefix(settings["DEBUG_MODE"]))

@cl.action_callback("select_model")
async def model_selected(action: cl.Action):
    model = action.payload["model"]
    cl.user_session.set("selected_model", model)
    
    model_label = models_utils.get_model_label(model)
    
    await cl.Message(
        content=f"{config.get_prefix(settings['DEBUG_MODE'])}âœ… ãƒ¢ãƒ‡ãƒ«ã€Œ{model_label}ã€ã‚’é¸æŠã—ã¾ã—ãŸã€‚è³ªå•ã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼",
        actions=ui_actions.common_actions(),
    ).send()

# â˜… ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
@cl.action_callback("upload_file")
async def upload_file_action(_):
    files = await cl.AskFileMessage(
        content="åˆ†æã—ãŸã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n"
                "ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼: CSV, Excel, ãƒ†ã‚­ã‚¹ãƒˆ, JSON, PDF, ç”»åƒ",
        accept=["text/csv", "application/vnd.ms-excel", 
                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
                "text/plain", "application/json", "application/pdf", 
                "image/png", "image/jpeg", "image/jpg"],
        max_size_mb=10,
        timeout=180,
    ).send()

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’åˆ‡ã‚Šå‡ºã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å§”è­²
    processed_files = await file_utils.handle_file_upload(files, settings["UPLOADS_DIR"])
    
    # å‡¦ç†ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
    current_files = cl.user_session.get("files", {})
    current_files.update(processed_files)
    cl.user_session.set("files", current_files)

@cl.action_callback("show_details")
async def show_file_details(action):
    file_name = action.payload["file_name"]
    files = cl.user_session.get("files", {})
    
    if file_name not in files:
        await cl.Message(content=f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
        return
    
    file_info = files[file_name]
    
    if file_info["type"] in ["csv", "excel"]:
        await file_utils.display_dataframe_details(file_info["dataframe"], file_name)
    elif file_info["type"] == "text":
        await cl.Message(
            content=f"### {file_name} ã®å…¨æ–‡:\n```\n{file_info['full_content']}\n```"
        ).send()
    elif file_info["type"] == "json":
        json_str = json.dumps(file_info["content"], indent=2, ensure_ascii=False)
        await cl.Message(
            content=f"### {file_name} ã®å†…å®¹:\n```json\n{json_str}\n```"
        ).send()
    else:
        await cl.Message(content=f"ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã®è©³ç´°è¡¨ç¤ºã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“: {file_info['type']}").send()

@cl.action_callback("analyze_file")
async def analyze_file(action):
    file_name = action.payload["file_name"]
    files = cl.user_session.get("files", {})
    
    if file_name not in files:
        await cl.Message(content=f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« {file_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
        return
    
    file_info = files[file_name]
    
    # ã“ã“ã§åˆã‚ã¦è©³ç´°ãªãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚’è¡Œã†
    try:
        await cl.Message(content=f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‚’è©³ç´°ã«åˆ†æã—ã¦ã„ã¾ã™...").send()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸå‡¦ç†
        if file_info["type"] == "csv":
            # ã“ã“ã§CSVã‚’èª­ã¿è¾¼ã‚€
            df = pd.read_csv(file_info["path"])
            file_info["dataframe"] = df
            csv_str = df.head(20).to_csv(index=False)
            prompt = (
                f"ä»¥ä¸‹ã®CSVãƒ‡ãƒ¼ã‚¿ï¼ˆã€Œ{file_name}ã€ã®æœ€åˆã®20è¡Œï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"
                "åŸºæœ¬çš„ãªçµ±è¨ˆæƒ…å ±ã€ãƒ‡ãƒ¼ã‚¿ã®å‚¾å‘ã€ãŠã‚ˆã³ç‰¹å¾´ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚\n\n"
                f"```\n{csv_str}\n```"
            )
        # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã‚‚åŒæ§˜ã«å‡¦ç†
        elif file_info["type"] == "pdf":
            prompt = f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚å†…å®¹ã®è¦ç´„ã‚„ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        else:
            prompt = f"ãƒ•ã‚¡ã‚¤ãƒ«ã€Œ{file_name}ã€ã®åˆ†æã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        
        # åˆ†æã®ãŸã‚ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡
        msg = cl.Message(content=prompt)
        await on_message(msg)
    
    except Exception as e:
        await cl.Message(content=f"ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}").send()

# â˜… åœæ­¢ãƒœã‚¿ãƒ³
@cl.action_callback("cancel")
async def cancel_stream(_):
    cl.user_session.set("cancel_flag", True)
    await cl.Message(
        content="â¹ ç”Ÿæˆã‚’åœæ­¢ã—ã¾ã™â€¦", 
        actions=ui_actions.common_actions(show_resume=True)
    ).send()

# â˜… å†é–‹ãƒœã‚¿ãƒ³
@cl.action_callback("resume")
async def resume_stream(_):
    last_user_msg = cl.user_session.get("last_user_msg")
    if not last_user_msg:
        await cl.Message(content="å†é–‹ã§ãã‚‹ä¼šè©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
        return
    # ã€Œç¶šãã‹ã‚‰ãŠé¡˜ã„ã—ã¾ã™ã€ã‚’è¿½åŠ ã—ã¦å†åº¦ ask_openai
    await on_message(cl.Message(content="ç¶šãã‹ã‚‰ãŠé¡˜ã„ã—ã¾ã™ã€‚", author="user", id="resume"), resume=True)

# â˜… ä¿å­˜ãƒœã‚¿ãƒ³ï¼ˆTXTãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã¿ï¼‰
@cl.action_callback("save")
async def save_history(_):
    history = cl.user_session.get("chat_history", [])
    if not history:
        return
    
    # TXTå½¢å¼ã§ä¿å­˜
    txt_fp = history_utils.save_chat_history_txt(
        history, 
        settings["CHAT_LOG_DIR"], 
        settings["SESSION_ID"], 
        is_manual=True
    )
    
    # ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
    elements = [
        cl.File(
            name=txt_fp.name, 
            path=str(txt_fp), 
            display="inline", 
            mime="text/plain", 
            description="ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼ˆèª­ã¿ã‚„ã™ã„å½¢å¼ï¼‰"
        )
    ]
    
    await cl.Message(
        content=f"ã“ã®ãƒãƒ£ãƒãƒ«ã§ã®ã‚„ã‚Šå–ã‚Šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚\nä¿å­˜å…ˆ: {settings['CHAT_LOG_DIR']}",
        elements=elements
    ).send()

# â˜… ãƒ—ãƒ­ã‚»ã‚¹å®Œå…¨çµ‚äº†ãƒœã‚¿ãƒ³
@cl.action_callback("shutdown")
async def shutdown_app(_):
    await cl.Message(content="ğŸ”´ ã‚µãƒ¼ãƒãƒ¼ã‚’çµ‚äº†ã—ã¾ã™â€¦").send()
    await cl.sleep(0.1)  # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡çŒ¶äºˆ
    os._exit(0)          # å³ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ï¼ˆSystemExitã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çµ‚äº†ï¼‰

# ãƒ¡ã‚¤ãƒ³ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©
@cl.on_message
async def on_message(msg: cl.Message, resume: bool = False):
    """ãƒ¡ã‚¤ãƒ³ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©"""
    # äº‹å‰çŠ¶æ…‹ã®ãƒªã‚»ãƒƒãƒˆã¨å±¥æ­´å‡¦ç†
    cl.user_session.set("cancel_flag", False)
    history = cl.user_session.get("chat_history", [])
    
    if not resume:
        history.append({"role": "user", "content": msg.content})
        cl.user_session.set("last_user_msg", msg.content)

    model = cl.user_session.get("selected_model", "gpt-4o")
    stream_msg = await cl.Message(content="").send()

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãŒãªã„ã‹ãƒã‚§ãƒƒã‚¯
        files = cl.user_session.get("files", {})
        message_content = msg.content
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãŒã‚ã‚‹å ´åˆã€é–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¿½åŠ 
        message_content = file_utils.get_file_reference_content(message_content, files)
        
        stream = await models_utils.ask_openai(
            client, 
            message_content, 
            history, 
            model, 
            debug_mode=settings["DEBUG_MODE"]
        )
        assistant_text = ""

        async for chunk in stream:
            if cl.user_session.get("cancel_flag"):
                await stream.aclose()
                break

            delta = chunk.choices[0].delta.content
            if delta:
                assistant_text += delta
                stream_msg.content += delta
                await stream_msg.update()

        if not cl.user_session.get("cancel_flag"):
            history.append({"role": "assistant", "content": assistant_text})
            # è‡ªå‹•ä¿å­˜
            history_utils.save_chat_history_txt(
                history, 
                settings["CHAT_LOG_DIR"], 
                settings["SESSION_ID"]
            )

    except Exception as e:
        await cl.Message(content=f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}").send()

    finally:
        cl.user_session.set("chat_history", history)
        
        # åœæ­¢çŠ¶æ…‹ã«å¿œã˜ãŸãƒœã‚¿ãƒ³è¡¨ç¤º
        await cl.Message(
            content="âœ… å¿œç­”å®Œäº†ï¼æ¬¡ã®æ“ä½œã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
            actions=ui_actions.common_actions(show_resume=cl.user_session.get("cancel_flag"))
        ).send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
ãƒ»Chainlit å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ       : https://docs.chainlit.io
ãƒ»OpenAI Chat API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹   : https://platform.openai.com/docs/api-reference/chat
ãƒ»python-dotenv ä½¿ã„æ–¹            : https://pypi.org/project/python-dotenv/
"""