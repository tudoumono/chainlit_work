"""
main.py ï¼ Chainlit + OpenAI ãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª
=========================================
ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§ãƒãƒ£ãƒƒãƒˆ UI ãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ã€‚
åˆ©ç”¨è€…ã¯ã€ŒGPTâ€‘3.5 / GPTâ€‘4 / GPTâ€‘4oã€ã‚’é€”ä¸­ã§ã‚‚è‡ªç”±ã«åˆ‡ã‚Šæ›¿ãˆã¦å¯¾è©±ã§ãã¾ã™ã€‚

--------------------------------------------------------------------------
ğŸ’¡ "ã–ã£ãã‚Šå…¨ä½“åƒ"
--------------------------------------------------------------------------
1. **åˆæœŸåŒ–**      : ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ã€OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
2. **ãƒ¢ãƒ‡ãƒ«é¸æŠUI**: èµ·å‹•æ™‚ã«ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºï¼ˆ`show_model_selection()`ï¼‰
3. **ãƒãƒ£ãƒƒãƒˆå‡¦ç†**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’å—ã‘å–ã‚Šã€OpenAI ã¸å•åˆã›ã¦è¿”å´
4. **å±¥æ­´ä¿å­˜**    : ã€Œä¿å­˜ã€ãƒœã‚¿ãƒ³ã§ TXT ã«ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ & è‡ªå‹•TXTä¿å­˜æ©Ÿèƒ½è¿½åŠ 
5. **ãƒ¢ãƒ‡ãƒ«å¤‰æ›´**  : ã„ã¤ã§ã‚‚ã€Œãƒ¢ãƒ‡ãƒ«å¤‰æ›´ã€ãƒœã‚¿ãƒ³ã§å†é¸æŠã§ãã‚‹
6. **åœæ­¢ãƒ»å†é–‹**  : â¹ ã§ç”Ÿæˆä¸­æ–­ã€â–¶ ã§ç¶šãã‹ã‚‰å†é–‹
7. **ãƒ•ã‚¡ã‚¤ãƒ«æ·»ä»˜**: ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦å†…å®¹ã‚’åˆ†æ
8. **ç”»åƒå‡¦ç†**    : DALL-Eç”»åƒç”Ÿæˆã¨ç”»åƒURLã®è¡¨ç¤ºæ©Ÿèƒ½
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®èª­ã¿è¾¼ã¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os, json, sys
import base64
import re
import aiohttp
import tempfile
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Union, Optional

# â–¼ ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ï¼ˆå¤–éƒ¨ï¼‰ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from dotenv import load_dotenv, find_dotenv           # .env ã‹ã‚‰å¤‰æ•°ã‚’èª­ã‚€ãŠæ‰‹è»½ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
import chainlit as cl                    # ãƒãƒ£ãƒƒãƒˆUIã‚’è¶…ç°¡å˜ã«ä½œã‚Œã‚‹ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
from openai import AsyncOpenAI           # OpenAI (GPT ãªã©) ã¨ã‚„ã‚Šå–ã‚Šã™ã‚‹å…¬å¼ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1. åˆæœŸè¨­å®šã¨ãƒ‘ã‚¹è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Electronã‹ã‚‰æ¸¡ã•ã‚Œã‚‹EXE_DIRã‚’å–å¾—ï¼ˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
EXE_DIR = os.getenv("EXE_DIR", os.getcwd())

# é©åˆ‡ãª .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå„ªå…ˆé †ä½: env/.env > .envï¼‰
ENV_PATH = os.path.join(EXE_DIR, "env", ".env")
if os.path.exists(ENV_PATH):
    load_dotenv(ENV_PATH)
    print(f"Loading .env from: {ENV_PATH}")
else:
    # å¾“æ¥ã®ãƒ‘ã‚¹ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦ä½¿ç”¨
    load_dotenv(find_dotenv())
    print(f"Loading .env from default location")

# å„ç¨®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã¾ãŸã¯æ—¢å®šå€¤ã‚’ä½¿ç”¨ï¼‰
CONSOLE_LOG_DIR = os.getenv("CONSOLE_LOG_DIR", os.path.join(EXE_DIR, "chainlit"))
CHAT_LOG_DIR = os.getenv("CHAT_LOG_DIR", os.path.join(EXE_DIR, "logs"))
TEMP_DIR = os.path.join(EXE_DIR, "temp")  # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€æ™‚ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
IMG_DIR = os.path.join(TEMP_DIR, "images")  # ç”»åƒä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

# ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
print(f"[DEBUG] EXE_DIR: {EXE_DIR}")
print(f"[DEBUG] ENV_PATH: {ENV_PATH}")
print(f"[DEBUG] CONSOLE_LOG_DIR: {CONSOLE_LOG_DIR}")
print(f"[DEBUG] CHAT_LOG_DIR: {CHAT_LOG_DIR}")
print(f"[DEBUG] TEMP_DIR: {TEMP_DIR}")
print(f"[DEBUG] IMG_DIR: {IMG_DIR}")

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
os.makedirs(CONSOLE_LOG_DIR, exist_ok=True)
os.makedirs(CHAT_LOG_DIR, exist_ok=True)
os.makedirs(TEMP_DIR, exist_ok=True)
os.makedirs(IMG_DIR, exist_ok=True)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
DEBUG_MODE = os.getenv("DEBUG_MODE") == "1"
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
DALLE_MODEL = os.getenv("DALLE_MODEL", "dall-e-3")  # DALL-Eãƒ¢ãƒ‡ãƒ«è¨­å®š

# ã‚»ãƒƒã‚·ãƒ§ãƒ³IDï¼ˆãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è­˜åˆ¥å­ï¼‰
SESSION_ID = datetime.now().strftime("%Y%m%d_%H%M%S")

# ã“ã“ã§ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã¯ã¾ã ã—ãªã„ï¼ˆAPIã‚­ãƒ¼ãŒãªã„ã‹ã‚‚ã—ã‚Œãªã„ãŸã‚ï¼‰
client = None
if OPENAI_API_KEY:
    client = AsyncOpenAI(api_key=OPENAI_API_KEY)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2. "ã©ã®GPTã‚’ä½¿ã†ã‹" ã®ãƒªã‚¹ãƒˆå®šç¾©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODELS = [
    ("GPTâ€‘4.1 (é«˜ç²¾åº¦ãƒ»é•·æ–‡å‡¦ç†)", "gpt-4.1"),                 # ä¸€éƒ¨ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ã‚ã‚Š
    ("GPTâ€‘4o (ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«)", "gpt-4o"),                     # éŸ³å£°ãƒ»ç”»åƒå¯¾å¿œ
    ("GPTâ€‘4 (é«˜æ€§èƒ½)", "gpt-4"),                               # æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    ("GPTâ€‘4-1106-preview (é«˜é€Ÿ)", "gpt-4-1106-preview"),       # æ¨å¥¨è¨­å®šãŒå¤šã„
    ("GPTâ€‘3.5 Turbo (ã‚³ã‚¹ãƒˆé‡è¦–)", "gpt-3.5-turbo"),           # æœ€ã‚‚ä¸€èˆ¬çš„
    ("GPTâ€‘3.5 Turbo 1106 (å®‰å®šç‰ˆ)", "gpt-3.5-turbo-1106"),     # å®‰å®šå‹•ä½œ
    ("GPTâ€‘3.5 Turbo Instruct (å˜ç™ºå¿œç­”)", "gpt-3.5-turbo-instruct")  # å˜ç™ºæŒ‡ç¤º
]
get_prefix = lambda: "ğŸ› ï¸ã€ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã€‘\n" if DEBUG_MODE else ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3. ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è‡ªå‹•ä¿å­˜æ©Ÿèƒ½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_chat_history_txt(history, is_manual=False):
    """
    ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’TXTãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹
    is_manual: æ‰‹å‹•ä¿å­˜ã®å ´åˆã¯Trueï¼ˆä¿å­˜ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆï¼‰
    """
    if not history:
        return None
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯CHAT_LOG_DIRã‚’ä½¿ç”¨
    out_dir = Path(CHAT_LOG_DIR)
    out_dir.mkdir(exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆè‡ªå‹•ä¿å­˜ã¨æ‰‹å‹•ä¿å­˜ã§åŒºåˆ¥ï¼‰
    prefix = "manual" if is_manual else "auto"
    filename = f"{prefix}_chat_{SESSION_ID}.txt"
    filepath = out_dir / filename
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›
    lines = ["===== ãƒãƒ£ãƒƒãƒˆå±¥æ­´ =====", f"æ—¥æ™‚: {datetime.now():%Y/%m/%d %H:%M:%S}", ""]
    
    for i, msg in enumerate(history):
        role = msg.get("role", "unknown")
        content = msg.get("content", "")
        
        # å½¹å‰²ã«å¿œã˜ã¦æ•´å½¢ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‚’åˆ†ã‹ã‚Šã‚„ã™ãï¼‰
        if role == "user":
            lines.append(f"ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆè³ªå• {i//2+1}ï¼‰:")
        elif role == "assistant":
            lines.append(f"ğŸ¤– AIï¼ˆå›ç­” {i//2+1}ï¼‰:")
        else:
            lines.append(f"ğŸ“ {role}:")
        
        # å†…å®¹ã‚’è¿½åŠ ï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆä»˜ãï¼‰
        for line in content.split("\n"):
            lines.append(f"  {line}")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é–“ã«ç©ºè¡Œã‚’å…¥ã‚Œã‚‹
        lines.append("")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
    filepath.write_text("\n".join(lines), encoding="utf-8")
    
    return filepath

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4. å…±é€šã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆä¿å­˜ãƒ»ãƒ¢ãƒ‡ãƒ«å¤‰æ›´ãƒ»åœæ­¢ãƒ»å†é–‹ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def common_actions(show_resume: bool = False):
    """ç”»é¢ä¸‹ã«ä¸¦ã¹ã‚‹ãƒœã‚¿ãƒ³ã‚’å…±é€šé–¢æ•°ã§ç®¡ç†ï¼ˆDRYï¼‰"""
    base = [
        cl.Action(name="save",          label="ä¿å­˜",        payload={"action": "save"}),
        cl.Action(name="change_model",  label="ãƒ¢ãƒ‡ãƒ«å¤‰æ›´",  payload={"action": "change_model"}),
        cl.Action(name="cancel",        label="â¹ åœæ­¢",      payload={"action": "cancel"}),
        cl.Action(name="shutdown",      label="ğŸ”´ ãƒ—ãƒ­ã‚»ã‚¹å®Œå…¨çµ‚äº†", payload={"action": "shutdown"}),
    ]
    # åœæ­¢å¾Œã«ã ã‘ã€Œâ–¶ ç¶šãã€ãƒœã‚¿ãƒ³ã‚’å‡ºã™
    if show_resume:
        base.append(cl.Action(name="resume", label="â–¶ ç¶šã", payload={"action": "resume"}))
    return base

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5. ãƒ¢ãƒ‡ãƒ«é¸æŠUI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def show_model_selection():
    await cl.Message(
        content=f"{get_prefix()}ğŸ§  ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
        actions=[
            cl.Action(name="select_model", label=label, payload={"model": val})
            for label, val in MODELS
        ],
    ).send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6. ç”»åƒç”Ÿæˆã¨å‡¦ç†æ©Ÿèƒ½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def generate_image_dalle(prompt: str, size: str = "1024x1024", style: str = "vivid") -> Optional[str]:
    """
    DALL-E ã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’ç”Ÿæˆã™ã‚‹
    
    Args:
        prompt: ç”»åƒç”Ÿæˆã®æŒ‡ç¤ºãƒ†ã‚­ã‚¹ãƒˆ
        size: ç”»åƒã‚µã‚¤ã‚º ("1024x1024", "1792x1024", "1024x1792" ã®ã„ãšã‚Œã‹)
        style: ç”»åƒã‚¹ã‚¿ã‚¤ãƒ« ("vivid" ã¾ãŸã¯ "natural")
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸç”»åƒã®URLã€ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
    """
    if not client:
        return None
    
    try:
        response = await client.images.generate(
            model=DALLE_MODEL,
            prompt=prompt,
            size=size,
            quality="standard",
            style=style,
            n=1,
        )
        
        image_url = response.data[0].url
        return image_url
    except Exception as e:
        print(f"DALL-E ç”»åƒç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

async def download_image(url: str) -> Optional[str]:
    """
    ç”»åƒURLã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã™ã‚‹
    
    Args:
        url: ç”»åƒã®URL
        
    Returns:
        ä¿å­˜ã•ã‚ŒãŸç”»åƒã®ãƒ‘ã‚¹ã€ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼æ™‚ã¯None
    """
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
        file_name = f"image_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        file_path = os.path.join(IMG_DIR, file_name)
        
        # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        async with aiohttp.ClientSession() as session:
            async with session.get(url) as response:
                if response.status == 200:
                    with open(file_path, 'wb') as f:
                        f.write(await response.read())
                    return file_path
                else:
                    print(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ {response.status}")
                    return None
    except Exception as e:
        print(f"ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def extract_image_urls(text: str) -> List[str]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡ºã™ã‚‹
    
    Args:
        text: æ¤œç´¢å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        æŠ½å‡ºã•ã‚ŒãŸç”»åƒURLã®ãƒªã‚¹ãƒˆ
    """
    # ä¸€èˆ¬çš„ãªç”»åƒURLãƒ‘ã‚¿ãƒ¼ãƒ³
    url_pattern = r'https?://[^\s<>"]+\.(jpg|jpeg|png|gif|webp|bmp|svg)(?:\?[^\s<>"]*)?\b'
    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ç”»åƒè¨˜æ³•
    md_pattern = r'!\[.*?\]\((https?://[^\s<>"]+\.(jpg|jpeg|png|gif|webp|bmp|svg)(?:\?[^\s<>"]*)?\b)\)'
    
    # é€šå¸¸ã®URLã‚’æ¤œç´¢
    urls = re.findall(url_pattern, text, re.IGNORECASE)
    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã‹ã‚‰URLã‚’æŠ½å‡º
    md_matches = re.findall(md_pattern, text, re.IGNORECASE)
    
    # çµæœã‚’çµåˆ
    all_urls = []
    for url in urls:
        if url.startswith(('http://', 'https://')):
            all_urls.append(url)
    
    for md_match in md_matches:
        if md_match[0].startswith(('http://', 'https://')):
            all_urls.append(md_match[0])
    
    return list(set(all_urls))  # é‡è¤‡ã‚’é™¤å»

async def process_response_with_images(text: str) -> tuple[str, List]:
    """
    ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡ºã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤ºç”¨ã®ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹
    
    Args:
        text: OpenAIã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
        
    Returns:
        å‡¦ç†ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
    """
    image_urls = extract_image_urls(text)
    elements = []
    
    if not image_urls:
        return text, elements
    
    for url in image_urls:
        # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        image_path = await download_image(url)
        if image_path:
            # ç”»åƒã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆ
            img_name = os.path.basename(image_path)
            elements.append(cl.Image(path=image_path, name=img_name, display="inline"))
            
            # ãƒ†ã‚­ã‚¹ãƒˆå†…ã®URLã‚’ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«ç½®ãæ›ãˆã‚‹
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ç”»åƒè¨˜æ³•ã‚’æ¤œå‡ºã—ã¦ç½®æ›
            md_pattern = f'!\\[.*?\\]\\({re.escape(url)}\\)'
            if re.search(md_pattern, text):
                text = re.sub(md_pattern, f"[ç”»åƒ: {img_name}]", text)
            else:
                # é€šå¸¸ã®URLã‚’ç½®æ›
                text = text.replace(url, f"[ç”»åƒ: {img_name}]")
    
    return text, elements

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7. OpenAI ã¸è³ªå•ã‚’æŠ•ã’ã‚‹é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def ask_openai(user_message: str,
                     history: list[dict],
                     model: str,
                     files: List[Dict[str, Any]] = None,
                     temperature: float = 0.7,
                     max_tokens: int = 1024):
    """
    * æ™®æ®µ:   OpenAI ã«å•ã„åˆã‚ã›ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§è¿”ã™
    * ãƒ‡ãƒãƒƒã‚°: ãƒ€ãƒŸãƒ¼æ–‡å­—åˆ—ã‚’è¿”ã™
    
    files: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
    """
    if DEBUG_MODE:
        async def fake_stream():
            for chunk in ["ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰", "ã“ã‚Œã¯ ", "OpenAI ã‚’ ", "å‘¼ã³å‡ºã—ã¦ ", "ã„ã¾ã›ã‚“ã€‚"]:
                yield type("Chunk", (), {
                    "choices": [type("Choice", (), {
                        "delta": type("Delta", (), {"content": chunk})()
                    })()]
                })()
        return fake_stream()

    messages = history + [{"role": "user", "content": user_message}]
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›
    if files and model in ["gpt-4o", "gpt-4-vision"]:
        content_parts = []
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸éƒ¨åˆ†
        content_parts.append({"type": "text", "text": user_message})
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«éƒ¨åˆ†
        for file_info in files:
            if file_info["type"].startswith("image/"):
                try:
                    with open(file_info["path"], "rb") as img_file:
                        base64_image = base64.b64encode(img_file.read()).decode('utf-8')
                    
                    content_parts.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{file_info['type']};base64,{base64_image}"
                        }
                    })
                except Exception as e:
                    print(f"Error processing image {file_info['name']}: {e}")
        
        # æœ€å¾Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°
        messages[-1] = {"role": "user", "content": content_parts}
    
    return await client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
        stream=True,
    )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 8. ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ©Ÿèƒ½
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@cl.on_file_upload(accept=["text/plain", "application/pdf", "image/jpeg", "image/png"])
async def handle_file_upload(file: cl.File):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®ãƒãƒ³ãƒ‰ãƒ©"""
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜å…ˆãƒ‘ã‚¹
        file_path = os.path.join(TEMP_DIR, file.name)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ä¿å­˜
        content = await file.content()
        with open(file_path, "wb") as f:
            f.write(content)
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¿½åŠ 
        files = cl.user_session.get("files", [])
        file_info = {
            "name": file.name,
            "path": file_path,
            "type": file.mime,
            "size": len(content)
        }
        files.append(file_info)
        cl.user_session.set("files", files)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¨®é¡ã«å¿œã˜ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        file_type_msg = ""
        if file.mime.startswith("image/"):
            file_type_msg = "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«"
        elif file.mime == "text/plain":
            file_type_msg = "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«"
        elif file.mime == "application/pdf":
            file_type_msg = "PDFãƒ•ã‚¡ã‚¤ãƒ«"
        else:
            file_type_msg = f"{file.mime}ãƒ•ã‚¡ã‚¤ãƒ«"
        
        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡
        await cl.Message(
            content=f"âœ… {file_type_msg}ã€Œ{file.name}ã€ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚\nã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¤ã„ã¦è³ªå•ã—ã¦ãã ã•ã„ã€‚",
        ).send()
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é€ä¿¡
        await cl.Message(content=f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}").send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 9. ç”»åƒç”Ÿæˆã‚³ãƒãƒ³ãƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@cl.on_message(starts_with="/image")
async def handle_image_command(message: cl.Message):
    """
    /image ã‚³ãƒãƒ³ãƒ‰ã‚’å‡¦ç†ã™ã‚‹
    å½¢å¼: /image æç”»ã—ãŸã„ã‚‚ã®ã®èª¬æ˜
    
    ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
    --size=1024x1024 (1024x1024, 1792x1024, 1024x1792 ã®ã„ãšã‚Œã‹)
    --style=vivid (vivid ã¾ãŸã¯ natural)
    """
    # ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†
    content = message.content.replace("/image", "", 1).strip()
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®æŠ½å‡º
    size = "1024x1024"
    style = "vivid"
    
    # ã‚µã‚¤ã‚ºã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‡¦ç†
    size_match = re.search(r'--size=(\S+)', content)
    if size_match:
        size_value = size_match.group(1)
        if size_value in ["1024x1024", "1792x1024", "1024x1792"]:
            size = size_value
        content = re.sub(r'--size=\S+', '', content).strip()
    
    # ã‚¹ã‚¿ã‚¤ãƒ«ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‡¦ç†
    style_match = re.search(r'--style=(\S+)', content)
    if style_match:
        style_value = style_match.group(1).lower()
        if style_value in ["vivid", "natural"]:
            style = style_value
        content = re.sub(r'--style=\S+', '', content).strip()
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç©ºã®å ´åˆ
    if not content:
        await cl.Message(content="""
ç”»åƒã®èª¬æ˜ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ä¾‹:
`/image é’ã„æµ·ã¨ç™½ã„ç ‚æµœ`

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
`--size=1024x1024` (1024x1024, 1792x1024, 1024x1792 ã‹ã‚‰é¸æŠ)
`--style=vivid` (vivid ã¾ãŸã¯ natural)
        """).send()
        return
    
    # ç”Ÿæˆé–‹å§‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    await cl.Message(content=f"ğŸ¨ ã€Œ{content}ã€ã®ç”»åƒã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...\nã‚µã‚¤ã‚º: {size}, ã‚¹ã‚¿ã‚¤ãƒ«: {style}").send()
    
    try:
        # ç”»åƒç”ŸæˆAPIå‘¼ã³å‡ºã—
        image_url = await generate_image_dalle(content, size, style)
        
        if image_url:
            # ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è¡¨ç¤º
            image_path = await download_image(image_url)
            
            if image_path:
                img_name = os.path.basename(image_path)
                elements = [cl.Image(path=image_path, name=img_name, display="inline")]
                
                await cl.Message(
                    content=f"âœ… ç”»åƒãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ:\n**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: {content}",
                    elements=elements
                ).send()
            else:
                await cl.Message(content="âŒ ç”»åƒã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚").send()
        else:
            await cl.Message(content="âŒ ç”»åƒã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚").send()
    
    except Exception as e:
        await cl.Message(content=f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}").send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 10. Chainlit ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@cl.on_chat_start
async def start():
    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    try:
        for file in os.listdir(TEMP_DIR):
            file_path = os.path.join(TEMP_DIR, file)
            if os.path.isfile(file_path):
                os.remove(file_path)
    except Exception as e:
        print(f"Error cleaning up temp directory: {e}")
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ•°ã®åˆæœŸåŒ–
    cl.user_session.set("files", [])
    
    if not OPENAI_API_KEY:
        # ğŸ”½ UIå´ã«è­¦å‘Šã‚’è¡¨ç¤º
        await cl.Message(
            content="âŒ **OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼**\n"
                    "`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®ã‚ˆã†ã«è¨­å®šã—ã¦ãã ã•ã„ï¼š\n"
                    "`OPENAI_API_KEY=\"sk-xxxx...\"`\n"
                    "ï¼ˆãƒ‡ãƒãƒƒã‚°ï¼‰ã“ã‚Œã¯ OpenAI ã‚’ å‘¼ã³å‡ºã—ã¦ ã„ã¾ã›ã‚“ã€‚\n"
                    "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\n"
                    ,
            actions=common_actions(),
        ).send()
        return

    # âœ… é€šå¸¸ã®é–‹å§‹å‡¦ç†
    await cl.Message(
        content="""âœ… Chainlitã‚’èµ·å‹•ã—ã¾ã—ãŸã€‚

**åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½:**
- ç”»é¢å·¦ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™
- `/image [èª¬æ˜]` ã‚³ãƒãƒ³ãƒ‰ã§ç”»åƒã‚’ç”Ÿæˆã§ãã¾ã™
  ä¾‹: `/image å¯Œå£«å±±ã¨æ¡œã®é¢¨æ™¯ --size=1024x1024 --style=vivid`
""",
    ).send()
    await show_model_selection()

@cl.action_callback("change_model")
async def change_model(_):
    await show_model_selection()

@cl.action_callback("select_model")
async def model_selected(action: cl.Action):
    cl.user_session.set("selected_model", action.payload["model"])
    await cl.Message(
        content=f"{get_prefix()}âœ… ãƒ¢ãƒ‡ãƒ«ã€Œ{action.payload['model']}ã€ã‚’é¸æŠã—ã¾ã—ãŸã€‚è³ªå•ã‚’ã©ã†ãï¼",
        actions=common_actions(),
    ).send()

# â˜… åœæ­¢ãƒœã‚¿ãƒ³
@cl.action_callback("cancel")
async def cancel_stream(_):
    cl.user_session.set("cancel_flag", True)
    await cl.Message(content="â¹ ç”Ÿæˆã‚’åœæ­¢ã—ã¾ã™â€¦", actions=common_actions(show_resume=True)).send()

# â˜… å†é–‹ãƒœã‚¿ãƒ³
@cl.action_callback("resume")
async def resume_stream(_):
    last_user_msg = cl.user_session.get("last_user_msg")
    if not last_user_msg:
        await cl.Message(content="å†é–‹ã§ãã‚‹ä¼šè©±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚").send()
        return
    # ã€Œç¶šãã‹ã‚‰ãŠé¡˜ã„ã—ã¾ã™ã€ã‚’è¿½åŠ ã—ã¦å†åº¦ ask_openai
    await on_message(cl.Message(content="ç¶šãã‹ã‚‰ãŠé¡˜ã„ã—ã¾ã™ã€‚", author="user", id="resume"), resume=True)

# â˜… ä¿å­˜ãƒœã‚¿ãƒ³ï¼ˆTXTãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã¿ï¼‰
@cl.action_callback("save")
async def save_history(_):
    history = cl.user_session.get("chat_history", [])
    if not history:
        return
    
    # JSONå½¢å¼ã§ã®ä¿å­˜ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
    # out_dir = Path(CHAT_LOG_DIR)
    # out_dir.mkdir(exist_ok=True)
    # json_fp = out_dir / f"manual_chat_{SESSION_ID}.json"
    # json_fp.write_text(json.dumps(history, indent=2, ensure_ascii=False), encoding="utf-8")
    
    # TXTå½¢å¼ã§ä¿å­˜
    txt_fp = save_chat_history_txt(history, is_manual=True)
    
    # ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
    elements = [
        cl.File(name=txt_fp.name, path=str(txt_fp), display="inline", 
                mime="text/plain", description="ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ï¼ˆèª­ã¿ã‚„ã™ã„å½¢å¼ï¼‰")
    ]
    
    await cl.Message(
        content=f"ã“ã®ãƒãƒ£ãƒãƒ«ã§ã®ã‚„ã‚Šå–ã‚Šã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚\nä¿å­˜å…ˆ: {CHAT_LOG_DIR}",
        elements=elements
    ).send()

# â˜… ãƒ—ãƒ­ã‚»ã‚¹å®Œå…¨çµ‚äº†ãƒœã‚¿ãƒ³
@cl.action_callback("shutdown")
async def shutdown_app(_):
    await cl.Message(content="ğŸ”´ ã‚µãƒ¼ãƒãƒ¼ã‚’çµ‚äº†ã—ã¾ã™â€¦").send()
    await cl.sleep(0.1)           # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡çŒ¶äºˆ
    os._exit(0)                   # å³ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†ï¼ˆSystemExitã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çµ‚äº†ï¼‰

# ãƒ¡ã‚¤ãƒ³ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒ³ãƒ‰ãƒ©
@cl.on_message
async def on_message(msg: cl.Message, resume: bool = False):
    """
    resume=True ã®ã¨ãã¯ã€Œç¶šãã‹ã‚‰ãŠé¡˜ã„ã—ã¾ã™ã€ãªã©ã®å†…éƒ¨å‘¼ã³å‡ºã—ç”¨
    """
    # /imageã‚³ãƒãƒ³ãƒ‰ã¯åˆ¥ã®ãƒãƒ³ãƒ‰ãƒ©ã§å‡¦ç†
    if msg.content.startswith("/image") and not resume:
        return
    
    # -- äº‹å‰ãƒªã‚»ãƒƒãƒˆã¨å±¥æ­´å‡¦ç† ------------------------------
    cl.user_session.set("cancel_flag", False)             # â˜… åœæ­¢ãƒ•ãƒ©ã‚°ã‚’æ¯å›ãƒªã‚»ãƒƒãƒˆ
    history = cl.user_session.get("chat_history", [])
    files = cl.user_session.get("files", [])
    
    if not resume:                                        # æœ¬æ¥ã®ãƒ¦ãƒ¼ã‚¶å…¥åŠ›ã ã‘å±¥æ­´ã«æ®‹ã™
        history.append({"role": "user", "content": msg.content})
        cl.user_session.set("last_user_msg", msg.content) # â˜… å†é–‹ç”¨ã«ä¿æŒ

    model = cl.user_session.get("selected_model", "gpt-4o")

    # ç©ºãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œã£ã¦ã€ã‚ã¨ã§é€æ¬¡ update()
    stream_msg = await cl.Message(content="").send()

    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒã‚ã‚Œã°ãã‚Œã‚‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«å«ã‚ã‚‹
        user_message = msg.content
        if files and not resume:
            file_context = _generate_file_context(files)
            if file_context:
                # å±¥æ­´ã«è¡¨ç¤ºã•ã‚Œã‚‹å†…å®¹ã¯ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã¾ã¾
                # OpenAIã«é€ä¿¡ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’ä»˜åŠ 
                user_message = f"{file_context}\n\nè³ªå•: {msg.content}"
        
        # OpenAIã«å•ã„åˆã‚ã›
        stream = await ask_openai(user_message, history, model, files if model in ["gpt-4o", "gpt-4-vision"] else None)
        assistant_text = ""

        async for chunk in stream:
            # â˜… åœæ­¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰ break
            if cl.user_session.get("cancel_flag"):
                await stream.aclose()     # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‰ã˜ã¦å³çµ‚äº†
                break

            delta = chunk.choices[0].delta.content
            if delta:
                assistant_text += delta
                stream_msg.content += delta
                await stream_msg.update()

        if not cl.user_session.get("cancel_flag"):
            # ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ç”»åƒURLã‚’å‡¦ç†
            processed_text, image_elements = await process_response_with_images(assistant_text)
            
            # ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’å«ã‚€å¿œç­”ã‚’é€ä¿¡
            if image_elements and processed_text != assistant_text:
                # å…ƒã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°ï¼ˆç”»åƒURLã‚’ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«å¤‰æ›´ï¼‰
                stream_msg.content = processed_text
                await stream_msg.update()
                
                # ç”»åƒã‚’å«ã‚€è¿½åŠ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡
                if image_elements:
                    await cl.Message(
                        content="ä»¥ä¸‹ã¯å¿œç­”å†…ã§è¨€åŠã•ã‚ŒãŸç”»åƒã§ã™ï¼š",
                        elements=image_elements
                    ).send()
            
            # å±¥æ­´ã«ä¿å­˜ï¼ˆå…ƒã®ãƒ†ã‚­ã‚¹ãƒˆï¼‰
            history.append({"role": "assistant", "content": assistant_text})
            
            # è‡ªå‹•ä¿å­˜æ©Ÿèƒ½
            save_chat_history_txt(history)

    except Exception as e:
        await cl.Message(content=f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}").send()

    finally:
        cl.user_session.set("chat_history", history)

        # â˜… åœæ­¢ã•ã‚ŒãŸå ´åˆã¯ â–¶ ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã€ãã‚Œä»¥å¤–ã¯é€šå¸¸ãƒœã‚¿ãƒ³
        await cl.Message(
            content="âœ… å¿œç­”å®Œäº†ï¼æ¬¡ã®æ“ä½œã‚’é¸ã‚“ã§ãã ã•ã„ï¼š",
            actions=common_actions(show_resume=cl.user_session.get("cancel_flag"))
        ).send()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 11. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _generate_file_context(files: List[Dict[str, Any]]) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—ã‚’ç”Ÿæˆã™ã‚‹"""
    if not files:
        return ""
    
    context = "ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢ã™ã‚‹è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š\n\n"
    
    for i, file_info in enumerate(files):
        context += f"ã€ãƒ•ã‚¡ã‚¤ãƒ«{i+1}ã€‘åå‰: {file_info['name']}, ã‚¿ã‚¤ãƒ—: {file_info['type']}\n"
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
        if file_info["type"] == "text/plain":
            try:
                with open(file_info["path"], "r", encoding="utf-8") as f:
                    content = f.read()
                    # é•·ã™ãã‚‹å ´åˆã¯å…ˆé ­éƒ¨åˆ†ã®ã¿
                    if len(content) > 2000:
                        content = content[:2000] + "...(ä»¥ä¸‹çœç•¥)..."
                    context += f"å†…å®¹:\n{content}\n\n"
            except Exception as e:
                context += f"ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {str(e)}\n\n"
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        elif file_info["type"].startswith("image/"):
            if "gpt-4o" in cl.user_session.get("selected_model", ""):
                context += "(ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ç”»åƒãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦åˆ¥é€”é€ä¿¡ã•ã‚Œã¾ã™)\n\n"
            else:
                context += "â€»ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç†è§£ã™ã‚‹ã«ã¯ GPT-4o ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„\n\n"
        # PDFãªã©ã€ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«
        else:
            context += f"(ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—ã®å†…å®¹ã¯ç›´æ¥å‡¦ç†ã§ãã¾ã›ã‚“)\n\n"
    
    return context

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
ãƒ»Chainlit å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ       : https://docs.chainlit.io
ãƒ»OpenAI Chat API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹   : https://platform.openai.com/docs/api-reference/chat
ãƒ»python-dotenv ä½¿ã„æ–¹            : https://pypi.org/project/python-dotenv/
"""